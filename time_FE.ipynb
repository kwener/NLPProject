{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPProject.ipynb  NLPProject3.ipynb manner_FE.ipynb   time_FE.ipynb\n",
      "NLPProject2.ipynb degree_FE.ipynb   place_FE.ipynb\n",
      "Notebook metadata fixed! You can now commit to GitHub.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#from google.colab import drive\n",
    "\n",
    "# Get the notebook's filename (usually matches the GitHub repo name)\n",
    "!ls *.ipynb\n",
    "notebook_name = \"NLPProject.ipynb\"  # ‚Üê Replace with your filename\n",
    "\n",
    "# Load and fix the notebook\n",
    "with open(notebook_name, 'r') as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "# Option A: Remove widgets metadata completely (recommended)\n",
    "if 'metadata' in nb and 'widgets' in nb['metadata']:\n",
    "    del nb['metadata']['widgets']\n",
    "\n",
    "# Option B: Or add the missing state key\n",
    "# if 'metadata' in nb and 'widgets' in nb['metadata']:\n",
    "#     nb['metadata']['widgets']['state'] = {}\n",
    "\n",
    "# Save the fixed version\n",
    "with open(notebook_name, 'w') as f:\n",
    "    json.dump(nb, f)\n",
    "\n",
    "print(\"Notebook metadata fixed! You can now commit to GitHub.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package framenet_v17 to\n",
      "[nltk_data]     /Users/kierstenwener/nltk_data...\n",
      "[nltk_data]   Package framenet_v17 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from operator import itemgetter\n",
    "import nltk\n",
    "from nltk.corpus import framenet as fn\n",
    "from nltk.corpus.reader.framenet import PrettyList\n",
    "nltk.download('framenet_v17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_with_time_ex = {}\n",
    "for f in fn.frames():\n",
    "    for x in f.FE:\n",
    "        if x == \"Time\":\n",
    "            frames_with_time_ex[f.name] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(text, char_labels, offsets):\n",
    "    token_labels = []\n",
    "    for start, end in offsets:\n",
    "        if start == end:\n",
    "            token_labels.append(\"O\")  # Special tokens like [CLS], [SEP]\n",
    "        else:\n",
    "            # Majority vote over character labels inside the token span\n",
    "            span_labels = char_labels[start:end]\n",
    "            if all(lab == \"O\" for lab in span_labels):\n",
    "                token_labels.append(\"O\")\n",
    "            elif span_labels[0] == \"B-Time\":\n",
    "                token_labels.append(\"B-Time\")\n",
    "            else:\n",
    "                token_labels.append(\"I-Time\")\n",
    "    return token_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kierstenwener/Desktop/NLPProject/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shapes:\n",
      "Input IDs: torch.Size([9013, 128])\n",
      "Attention Masks: torch.Size([9013, 128])\n",
      "Labels: torch.Size([9013, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from nltk.corpus import framenet as fn\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Map BIO tags to IDs\n",
    "label2id = {\"O\": 0, \"B-Time\": 1, \"I-Time\": 2}\n",
    "input_ids_list = []\n",
    "attention_masks_list = []\n",
    "labels_list = []\n",
    "\n",
    "# Find frames that include \"Time\" as a frame element\n",
    "\n",
    "for name, frame in frames_with_time_ex.items():\n",
    "    # Print the frame name for reference\n",
    "    for lu in frame.lexUnit.values():\n",
    "        #print(f\"\\nLexical Unit: {lu['name']}\")\n",
    "        lu_data = fn.lu(lu['ID'])\n",
    "        for ex in lu_data['exemplars']:\n",
    "            text = ex['text']\n",
    "            char_labels = [\"O\"] * len(text)\n",
    "            has_time_fe = False\n",
    "\n",
    "            for fe in ex['FE']:\n",
    "                for i in fe:\n",
    "                    if i[2] == \"Time\":\n",
    "                        start, end = i[0], i[1]\n",
    "                        if start < end:\n",
    "                            char_labels[start] = \"B-Time\"\n",
    "                            for i in range(start+1, end):\n",
    "                                char_labels[i] = \"I-Time\"\n",
    "                            has_time_fe = True\n",
    "            if not has_time_fe:\n",
    "                continue\n",
    "\n",
    "\n",
    "            # Tokenize\n",
    "            tokenized = tokenizer(text, return_offsets_mapping=True, truncation=True, padding=\"max_length\", max_length=128)\n",
    "            input_ids = tokenized[\"input_ids\"]\n",
    "            attention_mask = tokenized[\"attention_mask\"]\n",
    "            offsets = tokenized[\"offset_mapping\"]\n",
    "\n",
    "            # Map character-level labels to token-level labels\n",
    "            token_labels = align_labels_with_tokens(text, char_labels, offsets)\n",
    "            label2id_binary = {\"O\": 0, \"B-Time\": 1, \"I-Time\": 2}  \n",
    "            # Pad remaining labels with -100 where attention mask is 0 (i.e., padding tokens)\n",
    "\n",
    "\n",
    "            label_ids = [label2id_binary.get(lab, 0) for lab in token_labels]\n",
    "            label_ids = [\n",
    "                label if mask == 1 else -100 \n",
    "                for label, mask in zip(label_ids, attention_mask)\n",
    "            ]\n",
    "            # Store tensors\n",
    "            input_ids_list.append(torch.tensor(input_ids))\n",
    "            attention_masks_list.append(torch.tensor(attention_mask))\n",
    "            labels_list.append(torch.tensor(label_ids))\n",
    "\n",
    "# Final dataset tensors\n",
    "input_ids_tensor = torch.stack(input_ids_list)\n",
    "attention_masks_tensor = torch.stack(attention_masks_list)\n",
    "labels_tensor = torch.stack(labels_list)\n",
    "\n",
    "print(\"Tensor shapes:\")\n",
    "print(\"Input IDs:\", input_ids_tensor.shape)\n",
    "print(\"Attention Masks:\", attention_masks_tensor.shape)\n",
    "print(\"Labels:\", labels_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "dataset = TensorDataset(input_ids_tensor, attention_masks_tensor, labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SubsetRandomSampler\n",
    "from torch.utils.data import random_split\n",
    "# Parameters\n",
    "batch_size = 5\n",
    "validation_split = 0.5\n",
    "\n",
    "train_size = int((1 - validation_split) * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),  # Shuffle the data\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Create DataLoader for validation (without shuffling)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    sampler=SubsetRandomSampler(range(len(val_dataset))),  # Don't shuffle validation data\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "class FrameElementClassifier(nn.Module):\n",
    "    def __init__(self, bert_model='bert-base-uncased'):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model)\n",
    "        #self.query_encoder = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size)\n",
    "        self.token_projection = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 3)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    #def forward(self, input_ids, attention_mask, role_ids, role_mask):\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Encode sentence\n",
    "        sentence_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        token_embeddings = sentence_outputs.last_hidden_state  # shape: (B, T, H)\n",
    "\n",
    "        # Project sentence tokens\n",
    "        token_embeddings = self.token_projection(token_embeddings)  # shape: (B, T, H)\n",
    "        logits = self.classifier(token_embeddings)\n",
    "\n",
    "        return logits  # Apply softmax for inference or use with CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "accuracies = []\n",
    "num_batches = 15\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FrameElementClassifier().to(device)\n",
    "#class_weights = torch.tensor([0.4, 0.6]).to(device)  # Make time more important\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions_batch = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        input_ids, attention_mask, target_index = [item.to(device) for item in batch]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        probs = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(probs.view(-1, 3), target_index.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def fix_bio_predictions2(predictions):\n",
    "    corrected = []\n",
    "    batch_size, seq_len = predictions.shape\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        sentence = predictions[i].tolist()\n",
    "        sentence_corrected = sentence.copy()\n",
    "\n",
    "        for j in range(seq_len-1):\n",
    "            if sentence[j] == 2:  # I-Time\n",
    "                if j == 0:\n",
    "                    # Beginning of sequence, can't be I-Time\n",
    "                    sentence_corrected[j] = 0\n",
    "\n",
    "                elif sentence[j-1] == 0:\n",
    "                    # Look ahead to see if more 2's follow\n",
    "                    if sentence[j+1] == 2:\n",
    "                        if j > 2 and sentence[j-2] == 0:\n",
    "                            sentence_corrected[j-1] = 1\n",
    "                            sentence_corrected[j] = sentence[j]\n",
    "                        else:\n",
    "                            sentence_corrected[j-1] = 2\n",
    "                            sentence_corrected[j] = sentence[j]\n",
    "                    else: \n",
    "                        sentence_corrected[j] = 0\n",
    "                else:\n",
    "                    sentence_corrected[j] = sentence[j]\n",
    "            else:\n",
    "                sentence_corrected[j] = sentence[j]\n",
    "\n",
    "\n",
    "\n",
    "        corrected.append(sentence_corrected)\n",
    "\n",
    "    return torch.tensor(corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (O, B-Time, I-Time):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.96      0.97      0.97      1923\n",
      "      B-Time       0.74      0.81      0.77        80\n",
      "      I-Time       0.75      0.70      0.72       207\n",
      "\n",
      "    accuracy                           0.94      2210\n",
      "   macro avg       0.82      0.82      0.82      2210\n",
      "weighted avg       0.94      0.94      0.94      2210\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1859   20   44]\n",
      " [  10   65    5]\n",
      " [  60    3  144]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(val_dataloader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        input_ids, attention_mask, target_index = [item.to(device) for item in batch]\n",
    "\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        #gives index of highest scoring class\n",
    "        predicted_tokens = torch.argmax(logits, dim=-1)\n",
    "        fixed_predictions = fix_bio_predictions2(predicted_tokens)\n",
    "\n",
    "        mask = (target_index != -100)\n",
    "\n",
    "        all_true_labels.extend(target_index[mask].view(-1).cpu().numpy())\n",
    "        all_pred_labels.extend(fixed_predictions[mask].view(-1).cpu().numpy())\n",
    "\n",
    "# Report\n",
    "print(\"Classification Report (O, B-Time, I-Time):\")\n",
    "print(classification_report(all_true_labels, all_pred_labels, target_names=['O', 'B-Time', 'I-Time']))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix for Time FE Detection')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Accuracy: 1859/1923 = 0.9667\n",
      "B-Time Accuracy: 65/80 = 0.8125\n",
      "I-Time Accuracy: 144/207 = 0.6957\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "true_np = np.array(all_true_labels)\n",
    "pred_np = np.array(all_pred_labels)\n",
    "\n",
    "for label_id, label_name in enumerate(['O', 'B-Time', 'I-Time']):\n",
    "    total = np.sum(true_np == label_id)\n",
    "    correct = np.sum((true_np == label_id) & (pred_np == label_id))\n",
    "    print(f\"{label_name} Accuracy: {correct}/{total} = {correct/total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "def evaluate_model_postprocessed(model, val_dataloader, device):\n",
    "    model.eval()\n",
    "    true_labels_all = []\n",
    "    pred_labels_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader):\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            raw_preds = torch.argmax(outputs, dim=-1)  # (B, T)\n",
    "            fixed_preds = fix_bio_predictions2(raw_preds)  # Apply post-processing\n",
    "\n",
    "            for label_seq, pred_seq, mask in zip(labels, fixed_preds, attention_mask):\n",
    "                # Remove padding and apply attention mask\n",
    "                true_seq = [label.item() for label, m in zip(label_seq, mask) if m == 1 and label != -100]\n",
    "                pred_seq = [pred.item() for pred, m in zip(pred_seq, mask) if m == 1]\n",
    "\n",
    "                true_labels_all.append(true_seq)\n",
    "                pred_labels_all.append(pred_seq[:len(true_seq)])\n",
    "\n",
    "    return evaluate_predictions(true_labels_all, pred_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_bio_spans(label_seq):\n",
    "    spans = []\n",
    "    start = None\n",
    "\n",
    "    for i, label in enumerate(label_seq):\n",
    "        if label == 1:  # B\n",
    "            if start is not None:\n",
    "                spans.append((start, i - 1))  # close previous span\n",
    "            start = i\n",
    "        elif label == 2:\n",
    "            if start is None:\n",
    "                # Ill-formed BIO (I without B) ‚Äî treat as beginning a new span\n",
    "                start = i\n",
    "        else:  # label == 0\n",
    "            if start is not None:\n",
    "                spans.append((start, i - 1))\n",
    "                start = None\n",
    "\n",
    "    if start is not None:\n",
    "        spans.append((start, len(label_seq) - 1))\n",
    "    \n",
    "    return spans\n",
    "\n",
    "def evaluate_predictions(true_labels_list, pred_labels_list):\n",
    "    strict_match = 0\n",
    "    partial_match = 0\n",
    "    total_spans = 0\n",
    "\n",
    "    for true_seq, pred_seq in zip(true_labels_list, pred_labels_list):\n",
    "        true_spans = extract_bio_spans(true_seq)\n",
    "        pred_spans = extract_bio_spans(pred_seq)\n",
    "        total_spans += len(true_spans)\n",
    "\n",
    "        for t_start, t_end in true_spans:\n",
    "            t_range = set(range(t_start, t_end + 1))\n",
    "            match_found = False\n",
    "            for p_start, p_end in pred_spans:\n",
    "                p_range = set(range(p_start, p_end + 1))\n",
    "                if t_range == p_range:\n",
    "                    strict_match += 1\n",
    "                    match_found = True\n",
    "                    break\n",
    "                elif t_range & p_range:\n",
    "                    match_found = True\n",
    "            if match_found:\n",
    "                partial_match += 1\n",
    "\n",
    "    return {\n",
    "        \"Total Time Elements\": total_spans,\n",
    "        \"Strict Matches\": strict_match,\n",
    "        \"Partial Matches\": partial_match,\n",
    "        \"Strict Accuracy\": strict_match / total_spans if total_spans > 0 else 0,\n",
    "        \"Partial Accuracy\": partial_match / total_spans if total_spans > 0 else 0\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 902/902 [03:06<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Post-Processed Evaluation Results:\n",
      "Total Time Elements: 4658\n",
      "Strict Matches: 3667\n",
      "Partial Matches: 4232\n",
      "Strict Accuracy: 0.787\n",
      "Partial Accuracy: 0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model_postprocessed(model, val_dataloader, device)\n",
    "\n",
    "print(\"üìä Post-Processed Evaluation Results:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v:.3f}\" if isinstance(v, float) else f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           O\n",
      "i               O\n",
      "want            O\n",
      "to              O\n",
      "go              O\n",
      "tomorrow        B-Time\n",
      ".               O\n",
      "[SEP]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# 2. Prepare a test sentence\n",
    "text = \"I want to go tomorrow.\"\n",
    "\n",
    "# Tokenize with offsets to possibly map back later (optional here)\n",
    "encoding = tokenizer(text, return_tensors=\"pt\", return_offsets_mapping=True,\n",
    "                     truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "input_ids = encoding[\"input_ids\"]        # shape: (1, 128)\n",
    "attention_mask = encoding[\"attention_mask\"]\n",
    "offsets = encoding[\"offset_mapping\"]\n",
    "\n",
    "# 3. Pass through the model\n",
    "with torch.no_grad():\n",
    "    logits = model(input_ids, attention_mask)  # shape: (1, 128, 3)\n",
    "    predictions2 = torch.argmax(logits, dim=-1)  # shape: (1, 128)\n",
    "    fixed_predictions = fix_bio_predictions2(predictions2)\n",
    "\n",
    "id2label = {0: \"O\", 1: \"B-Time\", 2: \"I-Time\"}\n",
    "predicted_tags2 = [id2label[i.item()] for i in fixed_predictions[0]]\n",
    "\n",
    "# 5. Get back tokens for visualization (optional)\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "for tok, tag in zip(tokens, predicted_tags2):\n",
    "    print(f\"{tok:15} {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def fix_bio_predictions3(predictions):\n",
    "    corrected = []\n",
    "    batch_size, seq_len = predictions.shape\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        sentence = predictions[i].tolist()\n",
    "        sentence_corrected = sentence.copy()\n",
    "\n",
    "        for j in range(seq_len):\n",
    "            tag = sentence[j]\n",
    "\n",
    "            if tag == 2:  # I-tag\n",
    "                if j == 0:\n",
    "                    # Can't start with I -> make it O\n",
    "                    sentence_corrected[j] = 0\n",
    "\n",
    "                elif sentence_corrected[j - 1] == 0:\n",
    "                    # Pattern: O I ...\n",
    "                    # Check if a run of I-tags follows\n",
    "                    run_length = 1\n",
    "                    k = j + 1\n",
    "                    while k < seq_len and sentence[k] == 2:\n",
    "                        run_length += 1\n",
    "                        k += 1\n",
    "\n",
    "                    if run_length >= 1:\n",
    "                        # Change the O (at j-1) to B\n",
    "                        sentence_corrected[j - 1] = 1\n",
    "                    else:\n",
    "                        # Lone I -> make it O\n",
    "                        sentence_corrected[j] = 0\n",
    "\n",
    "        corrected.append(sentence_corrected)\n",
    "\n",
    "    return torch.tensor(corrected, device=predictions.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "def evaluate_model_postprocessed2(model, val_dataloader, device):\n",
    "    model.eval()\n",
    "    true_labels_all = []\n",
    "    pred_labels_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader):\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            raw_preds = torch.argmax(outputs, dim=-1)  # (B, T)\n",
    "            fixed_preds = fix_bio_predictions3(raw_preds)  # Apply post-processing\n",
    "\n",
    "            for label_seq, pred_seq, mask in zip(labels, fixed_preds, attention_mask):\n",
    "                # Remove padding and apply attention mask\n",
    "                true_seq = [label.item() for label, m in zip(label_seq, mask) if m == 1 and label != -100]\n",
    "                pred_seq = [pred.item() for pred, m in zip(pred_seq, mask) if m == 1]\n",
    "\n",
    "                true_labels_all.append(true_seq)\n",
    "                pred_labels_all.append(pred_seq[:len(true_seq)])\n",
    "\n",
    "    return evaluate_predictions(true_labels_all, pred_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 902/902 [03:11<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Post-Processed Evaluation Results:\n",
      "Total Time Elements: 4658\n",
      "Strict Matches: 3671\n",
      "Partial Matches: 4281\n",
      "Strict Accuracy: 0.788\n",
      "Partial Accuracy: 0.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results2 = evaluate_model_postprocessed2(model, val_dataloader, device)\n",
    "\n",
    "print(\"üìä Post-Processed Evaluation Results:\")\n",
    "for k, v in results2.items():\n",
    "    print(f\"{k}: {v:.3f}\" if isinstance(v, float) else f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           O\n",
      "do              O\n",
      "you             O\n",
      "want            O\n",
      "to              O\n",
      "walk            O\n",
      "to              O\n",
      "the             O\n",
      "park            O\n",
      "at              B-Time\n",
      "three           I-Time\n",
      "?               O\n",
      "[SEP]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           B-Time\n",
      "[PAD]           I-Time\n",
      "[PAD]           I-Time\n",
      "[PAD]           I-Time\n",
      "[PAD]           I-Time\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           B-Time\n",
      "[PAD]           I-Time\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           B-Time\n",
      "[PAD]           I-Time\n",
      "[PAD]           I-Time\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# 2. Prepare a test sentence\n",
    "text = \"Do you want to walk to the park at three?\"\n",
    "\n",
    "# Tokenize with offsets to possibly map back later (optional here)\n",
    "encoding = tokenizer(text, return_tensors=\"pt\", return_offsets_mapping=True,\n",
    "                     truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "input_ids = encoding[\"input_ids\"]        # shape: (1, 128)\n",
    "attention_mask = encoding[\"attention_mask\"]\n",
    "offsets = encoding[\"offset_mapping\"]\n",
    "\n",
    "# 3. Pass through the model\n",
    "with torch.no_grad():\n",
    "    logits = model(input_ids, attention_mask)  # shape: (1, 128, 3)\n",
    "    predictions2 = torch.argmax(logits, dim=-1)  # shape: (1, 128)\n",
    "    fixed_preds = fix_bio_predictions3(predictions2)\n",
    "\n",
    "id2label = {0: \"O\", 1: \"B-Time\", 2: \"I-Time\"}\n",
    "predicted_tags2 = [id2label[i.item()] for i in fixed_preds[0]]\n",
    "\n",
    "# 5. Get back tokens for visualization (optional)\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "for tok, tag in zip(tokens, predicted_tags2):\n",
    "    print(f\"{tok:15} {tag}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
