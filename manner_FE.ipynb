{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPProject.ipynb  NLPProject2.ipynb NLPProject3.ipynb manner_FE.ipynb\n",
      "Notebook metadata fixed! You can now commit to GitHub.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#from google.colab import drive\n",
    "\n",
    "# Get the notebook's filename (usually matches the GitHub repo name)\n",
    "!ls *.ipynb\n",
    "notebook_name = \"NLPProject.ipynb\"  # ‚Üê Replace with your filename\n",
    "\n",
    "# Load and fix the notebook\n",
    "with open(notebook_name, 'r') as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "# Option A: Remove widgets metadata completely (recommended)\n",
    "if 'metadata' in nb and 'widgets' in nb['metadata']:\n",
    "    del nb['metadata']['widgets']\n",
    "\n",
    "# Option B: Or add the missing state key\n",
    "# if 'metadata' in nb and 'widgets' in nb['metadata']:\n",
    "#     nb['metadata']['widgets']['state'] = {}\n",
    "\n",
    "# Save the fixed version\n",
    "with open(notebook_name, 'w') as f:\n",
    "    json.dump(nb, f)\n",
    "\n",
    "print(\"Notebook metadata fixed! You can now commit to GitHub.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package framenet_v17 to\n",
      "[nltk_data]     /Users/kierstenwener/nltk_data...\n",
      "[nltk_data]   Package framenet_v17 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from operator import itemgetter\n",
    "import nltk\n",
    "from nltk.corpus import framenet as fn\n",
    "from nltk.corpus.reader.framenet import PrettyList\n",
    "nltk.download('framenet_v17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_with_manner_ex = {}\n",
    "for f in fn.frames():\n",
    "    for x in f.FE:\n",
    "        if x == \"Manner\":\n",
    "            frames_with_manner_ex[f.name] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(text, char_labels, offsets):\n",
    "    token_labels = []\n",
    "    for start, end in offsets:\n",
    "        if start == end:\n",
    "            token_labels.append(\"O\")  # Special tokens like [CLS], [SEP]\n",
    "        else:\n",
    "            # Majority vote over character labels inside the token span\n",
    "            span_labels = char_labels[start:end]\n",
    "            if all(lab == \"O\" for lab in span_labels):\n",
    "                token_labels.append(\"O\")\n",
    "            elif span_labels[0] == \"B-Manner\":\n",
    "                token_labels.append(\"B-Manner\")\n",
    "            else:\n",
    "                token_labels.append(\"I-Manner\")\n",
    "    return token_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kierstenwener/Desktop/NLPProject/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shapes:\n",
      "Input IDs: torch.Size([8064, 128])\n",
      "Attention Masks: torch.Size([8064, 128])\n",
      "Labels: torch.Size([8064, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from nltk.corpus import framenet as fn\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Map BIO tags to IDs\n",
    "label2id = {\"O\": 0, \"B-Manner\": 1, \"I-Manner\": 2}\n",
    "input_ids_list = []\n",
    "attention_masks_list = []\n",
    "labels_list = []\n",
    "\n",
    "# Find frames that include \"Manner\" as a frame element\n",
    "\n",
    "for name, frame in frames_with_manner_ex.items():\n",
    "    # Print the frame name for reference\n",
    "    for lu in frame.lexUnit.values():\n",
    "        #print(f\"\\nLexical Unit: {lu['name']}\")\n",
    "        lu_data = fn.lu(lu['ID'])\n",
    "        for ex in lu_data['exemplars']:\n",
    "            text = ex['text']\n",
    "            char_labels = [\"O\"] * len(text)\n",
    "            has_manner_fe = False\n",
    "\n",
    "            for fe in ex['FE']:\n",
    "                for i in fe:\n",
    "                    if i[2] == \"Manner\":\n",
    "                        start, end = i[0], i[1]\n",
    "                        if start < end:\n",
    "                            char_labels[start] = \"B-Manner\"\n",
    "                            for i in range(start+1, end):\n",
    "                                char_labels[i] = \"I-Manner\"\n",
    "                            has_manner_fe = True\n",
    "            if not has_manner_fe:\n",
    "                continue\n",
    "\n",
    "\n",
    "            # Tokenize\n",
    "            tokenized = tokenizer(text, return_offsets_mapping=True, truncation=True, padding=\"max_length\", max_length=128)\n",
    "            input_ids = tokenized[\"input_ids\"]\n",
    "            attention_mask = tokenized[\"attention_mask\"]\n",
    "            offsets = tokenized[\"offset_mapping\"]\n",
    "\n",
    "            # Map character-level labels to token-level labels\n",
    "            token_labels = align_labels_with_tokens(text, char_labels, offsets)\n",
    "            label2id_binary = {\"O\": 0, \"B-Manner\": 1, \"I-Manner\": 2}  # Map both B-Manner to 1 and I to 2\n",
    "            # Pad remaining labels with -100 where attention mask is 0 (i.e., padding tokens)\n",
    "\n",
    "\n",
    "            label_ids = [label2id_binary.get(lab, 0) for lab in token_labels]\n",
    "            label_ids = [\n",
    "                label if mask == 1 else -100 \n",
    "                for label, mask in zip(label_ids, attention_mask)\n",
    "            ]\n",
    "            # Store tensors\n",
    "            input_ids_list.append(torch.tensor(input_ids))\n",
    "            attention_masks_list.append(torch.tensor(attention_mask))\n",
    "            labels_list.append(torch.tensor(label_ids))\n",
    "\n",
    "# Final dataset tensors\n",
    "input_ids_tensor = torch.stack(input_ids_list)\n",
    "attention_masks_tensor = torch.stack(attention_masks_list)\n",
    "labels_tensor = torch.stack(labels_list)\n",
    "\n",
    "print(\"Tensor shapes:\")\n",
    "print(\"Input IDs:\", input_ids_tensor.shape)\n",
    "print(\"Attention Masks:\", attention_masks_tensor.shape)\n",
    "print(\"Labels:\", labels_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "dataset = TensorDataset(input_ids_tensor, attention_masks_tensor, labels_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SubsetRandomSampler\n",
    "from torch.utils.data import random_split\n",
    "# Parameters\n",
    "batch_size = 5\n",
    "validation_split = 0.5\n",
    "\n",
    "train_size = int((1 - validation_split) * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),  # Shuffle the data\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Create DataLoader for validation (without shuffling)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    sampler=SubsetRandomSampler(range(len(val_dataset))),  # Don't shuffle validation data\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "class FrameElementClassifier(nn.Module):\n",
    "    def __init__(self, bert_model='bert-base-uncased'):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model)\n",
    "        #self.query_encoder = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size)\n",
    "        self.token_projection = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 3)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    #def forward(self, input_ids, attention_mask, role_ids, role_mask):\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Encode sentence\n",
    "        sentence_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        token_embeddings = sentence_outputs.last_hidden_state  # shape: (B, T, H)\n",
    "\n",
    "        # Project sentence tokens\n",
    "        token_embeddings = self.token_projection(token_embeddings)  # shape: (B, T, H)\n",
    "        logits = self.classifier(token_embeddings)\n",
    "\n",
    "        return logits  # Apply softmax for inference or use with CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "accuracies = []\n",
    "num_batches = 15\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FrameElementClassifier().to(device)\n",
    "#class_weights = torch.tensor([0.4, 0.6]).to(device)  # Make manner more important\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions_batch = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        print(i)\n",
    "        input_ids, attention_mask, target_index = [item.to(device) for item in batch]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        probs = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(probs.view(-1, 3), target_index.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def fix_bio_predictions2(predictions):\n",
    "    corrected = []\n",
    "    batch_size, seq_len = predictions.shape\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        sentence = predictions[i].tolist()\n",
    "        sentence_corrected = sentence.copy()\n",
    "\n",
    "        for j in range(seq_len):\n",
    "            if sentence[j] == 2:  # I-Time\n",
    "                if j == 0:\n",
    "                    # Beginning of sequence, can't be I-Time\n",
    "                    sentence_corrected[j] = 0\n",
    "\n",
    "                elif sentence[j-1] == 0:\n",
    "                    # Look ahead to see if more 2's follow\n",
    "                    if sentence[j+1] == 2:\n",
    "                        sentence_corrected[j-1] = 2\n",
    "                        sentence_corrected[j] = sentence[j]\n",
    "                        \n",
    "                    else: \n",
    "                        sentence_corrected[j] = 0\n",
    "                else:\n",
    "                    sentence_corrected[j] = sentence[j]\n",
    "            else:\n",
    "                sentence_corrected[j] = sentence[j]\n",
    "\n",
    "\n",
    "\n",
    "        corrected.append(sentence_corrected)\n",
    "\n",
    "    return torch.tensor(corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (O, B-Manner, I-Manner):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.98      0.99      0.98      1962\n",
      "    B-Manner       0.88      0.75      0.81        75\n",
      "    I-Manner       0.76      0.75      0.75        80\n",
      "\n",
      "    accuracy                           0.97      2117\n",
      "   macro avg       0.87      0.83      0.85      2117\n",
      "weighted avg       0.97      0.97      0.97      2117\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1938    7   17]\n",
      " [  17   56    2]\n",
      " [  19    1   60]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(val_dataloader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        input_ids, attention_mask, target_index = [item.to(device) for item in batch]\n",
    "\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        predicted_tokens = torch.argmax(logits, dim=-1)\n",
    "        fixed_predictions = fix_bio_predictions2(predicted_tokens)\n",
    "\n",
    "        mask = (target_index != -100)\n",
    "\n",
    "        all_true_labels.extend(target_index[mask].view(-1).cpu().numpy())\n",
    "        all_pred_labels.extend(predicted_tokens[mask].view(-1).cpu().numpy())\n",
    "\n",
    "# Report\n",
    "print(\"Classification Report (O, B-Manner, I-Manner):\")\n",
    "print(classification_report(all_true_labels, all_pred_labels, target_names=['O', 'B-Manner', 'I-Manner']))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix for Time FE Detection')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Accuracy: 1938/1962 = 0.9878\n",
      "B-Manner Accuracy: 56/75 = 0.7467\n",
      "I-Manner Accuracy: 60/80 = 0.7500\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "true_np = np.array(all_true_labels)\n",
    "pred_np = np.array(all_pred_labels)\n",
    "\n",
    "for label_id, label_name in enumerate(['O', 'B-Manner', 'I-Manner']):\n",
    "    total = np.sum(true_np == label_id)\n",
    "    correct = np.sum((true_np == label_id) & (pred_np == label_id))\n",
    "    print(f\"{label_name} Accuracy: {correct}/{total} = {correct/total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "def evaluate_model_postprocessed(model, val_dataloader, device):\n",
    "    model.eval()\n",
    "    true_labels_all = []\n",
    "    pred_labels_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader):\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            raw_preds = torch.argmax(outputs, dim=-1)  # (B, T)\n",
    "            fixed_preds = fix_bio_predictions2(raw_preds)  # Apply post-processing\n",
    "\n",
    "            for label_seq, pred_seq, mask in zip(labels, fixed_preds, attention_mask):\n",
    "                # Remove padding and apply attention mask\n",
    "                true_seq = [label.item() for label, m in zip(label_seq, mask) if m == 1 and label != -100]\n",
    "                pred_seq = [pred.item() for pred, m in zip(pred_seq, mask) if m == 1]\n",
    "\n",
    "                true_labels_all.append(true_seq)\n",
    "                pred_labels_all.append(pred_seq[:len(true_seq)])\n",
    "\n",
    "    return evaluate_predictions(true_labels_all, pred_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_bio_spans(label_seq):\n",
    "    spans = []\n",
    "    start = None\n",
    "\n",
    "    for i, label in enumerate(label_seq):\n",
    "        if label == 1:  # B\n",
    "            if start is not None:\n",
    "                spans.append((start, i - 1))  # close previous span\n",
    "            start = i\n",
    "        elif label == 2:\n",
    "            if start is None:\n",
    "                # Ill-formed BIO (I without B) ‚Äî treat as beginning a new span\n",
    "                start = i\n",
    "        else:  # label == 0\n",
    "            if start is not None:\n",
    "                spans.append((start, i - 1))\n",
    "                start = None\n",
    "\n",
    "    if start is not None:\n",
    "        spans.append((start, len(label_seq) - 1))\n",
    "    \n",
    "    return spans\n",
    "\n",
    "def evaluate_predictions(true_labels_list, pred_labels_list):\n",
    "    strict_match = 0\n",
    "    partial_match = 0\n",
    "    total_spans = 0\n",
    "\n",
    "    for true_seq, pred_seq in zip(true_labels_list, pred_labels_list):\n",
    "        true_spans = extract_bio_spans(true_seq)\n",
    "        pred_spans = extract_bio_spans(pred_seq)\n",
    "        total_spans += len(true_spans)\n",
    "\n",
    "        for t_start, t_end in true_spans:\n",
    "            t_range = set(range(t_start, t_end + 1))\n",
    "            match_found = False\n",
    "            for p_start, p_end in pred_spans:\n",
    "                p_range = set(range(p_start, p_end + 1))\n",
    "                if t_range == p_range:\n",
    "                    strict_match += 1\n",
    "                    match_found = True\n",
    "                    break\n",
    "                elif t_range & p_range:\n",
    "                    match_found = True\n",
    "            if match_found:\n",
    "                partial_match += 1\n",
    "\n",
    "    return {\n",
    "        \"Total Time Elements\": total_spans,\n",
    "        \"Strict Matches\": strict_match,\n",
    "        \"Partial Matches\": partial_match,\n",
    "        \"Strict Accuracy\": strict_match / total_spans if total_spans > 0 else 0,\n",
    "        \"Partial Accuracy\": partial_match / total_spans if total_spans > 0 else 0\n",
    "    }\n",
    "\n",
    "# ‚¨áÔ∏è EVALUATION CODE\n",
    "def evaluate_model(model, val_dataloader, device):\n",
    "    model.eval()\n",
    "    true_labels_all = []\n",
    "    pred_labels_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader):\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predictions = torch.argmax(outputs, dim=-1)  # shape: (B, T)\n",
    "\n",
    "            for label_seq, pred_seq, mask in zip(labels, predictions, attention_mask):\n",
    "                # Remove padding (-100) and apply attention mask\n",
    "                true_seq = [label.item() for label, m in zip(label_seq, mask) if m == 1 and label != -100]\n",
    "                pred_seq = [pred.item() for pred, m in zip(pred_seq, mask) if m == 1]\n",
    "\n",
    "                true_labels_all.append(true_seq)\n",
    "                pred_labels_all.append(pred_seq[:len(true_seq)])  # Match lengths just in case\n",
    "\n",
    "    return evaluate_bio_predictions(true_labels_all, pred_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 807/807 [02:57<00:00,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Post-Processed Evaluation Results:\n",
      "Total Time Elements: 4115\n",
      "Strict Matches: 2854\n",
      "Partial Matches: 3277\n",
      "Strict Accuracy: 0.694\n",
      "Partial Accuracy: 0.796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model_postprocessed(model, val_dataloader, device)\n",
    "\n",
    "print(\"üìä Post-Processed Evaluation Results:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v:.3f}\" if isinstance(v, float) else f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           O\n",
      "they            O\n",
      "had             O\n",
      "to              O\n",
      "trek            O\n",
      "on              B-Manner\n",
      "foot            I-Manner\n",
      "through         O\n",
      "the             O\n",
      "desert          O\n",
      ".               O\n",
      "[SEP]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           B-Manner\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# 2. Prepare a test sentence\n",
    "text = \"They had to trek on foot through the desert.\"\n",
    "\n",
    "# Tokenize with offsets to possibly map back later (optional here)\n",
    "encoding = tokenizer(text, return_tensors=\"pt\", return_offsets_mapping=True,\n",
    "                     truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "input_ids = encoding[\"input_ids\"]        # shape: (1, 128)\n",
    "attention_mask = encoding[\"attention_mask\"]\n",
    "offsets = encoding[\"offset_mapping\"]\n",
    "\n",
    "# 3. Pass through the model\n",
    "with torch.no_grad():\n",
    "    logits = model(input_ids, attention_mask)  # shape: (1, 128, 3)\n",
    "    predictions2 = torch.argmax(logits, dim=-1)  # shape: (1, 128)\n",
    "\n",
    "id2label = {0: \"O\", 1: \"B-Manner\", 2: \"I-Manner\"}\n",
    "predicted_tags2 = [id2label[i.item()] for i in predictions2[0]]\n",
    "\n",
    "# 5. Get back tokens for visualization (optional)\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "for tok, tag in zip(tokens, predicted_tags2):\n",
    "    print(f\"{tok:15} {tag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def fix_bio_predictions3(predictions):\n",
    "    corrected = []\n",
    "    batch_size, seq_len = predictions.shape\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        sentence = predictions[i].tolist()\n",
    "        sentence_corrected = sentence.copy()\n",
    "\n",
    "        for j in range(seq_len):\n",
    "            tag = sentence[j]\n",
    "\n",
    "            if tag == 2:  # I-tag\n",
    "                if j == 0:\n",
    "                    # Can't start with I -> make it O\n",
    "                    sentence_corrected[j] = 0\n",
    "\n",
    "                elif sentence_corrected[j - 1] == 0:\n",
    "                    # Pattern: O I ...\n",
    "                    # Check if a run of I-tags follows\n",
    "                    run_length = 1\n",
    "                    k = j + 1\n",
    "                    while k < seq_len and sentence[k] == 2:\n",
    "                        run_length += 1\n",
    "                        k += 1\n",
    "\n",
    "                    if run_length >= 1:\n",
    "                        # Change the O (at j-1) to B\n",
    "                        sentence_corrected[j - 1] = 1\n",
    "                    else:\n",
    "                        # Lone I -> make it O\n",
    "                        sentence_corrected[j] = 0\n",
    "\n",
    "        corrected.append(sentence_corrected)\n",
    "\n",
    "    return torch.tensor(corrected, device=predictions.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "def evaluate_model_postprocessed2(model, val_dataloader, device):\n",
    "    model.eval()\n",
    "    true_labels_all = []\n",
    "    pred_labels_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader):\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            raw_preds = torch.argmax(outputs, dim=-1)  # (B, T)\n",
    "            fixed_preds = fix_bio_predictions3(raw_preds)  # Apply post-processing\n",
    "\n",
    "            for label_seq, pred_seq, mask in zip(labels, fixed_preds, attention_mask):\n",
    "                # Remove padding and apply attention mask\n",
    "                true_seq = [label.item() for label, m in zip(label_seq, mask) if m == 1 and label != -100]\n",
    "                pred_seq = [pred.item() for pred, m in zip(pred_seq, mask) if m == 1]\n",
    "\n",
    "                true_labels_all.append(true_seq)\n",
    "                pred_labels_all.append(pred_seq[:len(true_seq)])\n",
    "\n",
    "    return evaluate_predictions(true_labels_all, pred_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 807/807 [02:53<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Post-Processed Evaluation Results:\n",
      "Total Time Elements: 4115\n",
      "Strict Matches: 2874\n",
      "Partial Matches: 3361\n",
      "Strict Accuracy: 0.698\n",
      "Partial Accuracy: 0.817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results2 = evaluate_model_postprocessed2(model, val_dataloader, device)\n",
    "\n",
    "print(\"üìä Post-Processed Evaluation Results:\")\n",
    "for k, v in results2.items():\n",
    "    print(f\"{k}: {v:.3f}\" if isinstance(v, float) else f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           O\n",
      "he              O\n",
      "cleaned         O\n",
      "with            B-Manner\n",
      "a               O\n",
      "rag             O\n",
      "[SEP]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# 2. Prepare a test sentence\n",
    "text = \"He cleaned with a rag\"\n",
    "\n",
    "# Tokenize with offsets to possibly map back later (optional here)\n",
    "encoding = tokenizer(text, return_tensors=\"pt\", return_offsets_mapping=True,\n",
    "                     truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "input_ids = encoding[\"input_ids\"]        # shape: (1, 128)\n",
    "attention_mask = encoding[\"attention_mask\"]\n",
    "offsets = encoding[\"offset_mapping\"]\n",
    "\n",
    "# 3. Pass through the model\n",
    "with torch.no_grad():\n",
    "    logits = model(input_ids, attention_mask)  # shape: (1, 128, 3)\n",
    "    predictions2 = torch.argmax(logits, dim=-1)  # shape: (1, 128)\n",
    "    fixed_preds = fix_bio_predictions3(predictions2)\n",
    "\n",
    "id2label = {0: \"O\", 1: \"B-Manner\", 2: \"I-Manner\"}\n",
    "predicted_tags2 = [id2label[i.item()] for i in fixed_preds[0]]\n",
    "\n",
    "# 5. Get back tokens for visualization (optional)\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "for tok, tag in zip(tokens, predicted_tags2):\n",
    "    print(f\"{tok:15} {tag}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
