{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPProject.ipynb  NLPProject3.ipynb manner_FE.ipynb   time_FE.ipynb\n",
      "NLPProject2.ipynb degree_FE.ipynb   place_FE.ipynb\n",
      "Notebook metadata fixed! You can now commit to GitHub.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#from google.colab import drive\n",
    "\n",
    "# Get the notebook's filename (usually matches the GitHub repo name)\n",
    "!ls *.ipynb\n",
    "notebook_name = \"NLPProject.ipynb\"  # ‚Üê Replace with your filename\n",
    "\n",
    "# Load and fix the notebook\n",
    "with open(notebook_name, 'r') as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "# Option A: Remove widgets metadata completely (recommended)\n",
    "if 'metadata' in nb and 'widgets' in nb['metadata']:\n",
    "    del nb['metadata']['widgets']\n",
    "\n",
    "# Option B: Or add the missing state key\n",
    "# if 'metadata' in nb and 'widgets' in nb['metadata']:\n",
    "#     nb['metadata']['widgets']['state'] = {}\n",
    "\n",
    "# Save the fixed version\n",
    "with open(notebook_name, 'w') as f:\n",
    "    json.dump(nb, f)\n",
    "\n",
    "print(\"Notebook metadata fixed! You can now commit to GitHub.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package framenet_v17 to\n",
      "[nltk_data]     /Users/kierstenwener/nltk_data...\n",
      "[nltk_data]   Package framenet_v17 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from operator import itemgetter\n",
    "import nltk\n",
    "from nltk.corpus import framenet as fn\n",
    "from nltk.corpus.reader.framenet import PrettyList\n",
    "nltk.download('framenet_v17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_with_manner_ex = {}\n",
    "for f in fn.frames():\n",
    "    for x in f.FE:\n",
    "        if x == \"Manner\":\n",
    "            frames_with_manner_ex[f.name] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(text, char_labels, offsets):\n",
    "    token_labels = []\n",
    "    for start, end in offsets:\n",
    "        if start == end:\n",
    "            token_labels.append(\"O\")  # Special tokens like [CLS], [SEP]\n",
    "        else:\n",
    "            # Majority vote over character labels inside the token span\n",
    "            span_labels = char_labels[start:end]\n",
    "            if all(lab == \"O\" for lab in span_labels):\n",
    "                token_labels.append(\"O\")\n",
    "            elif span_labels[0] == \"B-Manner\":\n",
    "                token_labels.append(\"B-Manner\")\n",
    "            else:\n",
    "                token_labels.append(\"I-Manner\")\n",
    "    return token_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kierstenwener/Desktop/NLPProject/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shapes:\n",
      "Input IDs: torch.Size([8064, 128])\n",
      "Attention Masks: torch.Size([8064, 128])\n",
      "Labels: torch.Size([8064, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from nltk.corpus import framenet as fn\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Map BIO tags to IDs\n",
    "label2id = {\"O\": 0, \"B-Manner\": 1, \"I-Manner\": 2}\n",
    "input_ids_list = []\n",
    "attention_masks_list = []\n",
    "labels_list = []\n",
    "\n",
    "# Find frames that include \"Manner\" as a frame element\n",
    "\n",
    "for name, frame in frames_with_manner_ex.items():\n",
    "    # Print the frame name for reference\n",
    "    for lu in frame.lexUnit.values():\n",
    "        #print(f\"\\nLexical Unit: {lu['name']}\")\n",
    "        lu_data = fn.lu(lu['ID'])\n",
    "        for ex in lu_data['exemplars']:\n",
    "            text = ex['text']\n",
    "            char_labels = [\"O\"] * len(text)\n",
    "            has_manner_fe = False\n",
    "\n",
    "            for fe in ex['FE']:\n",
    "                for i in fe:\n",
    "                    if i[2] == \"Manner\":\n",
    "                        start, end = i[0], i[1]\n",
    "                        if start < end:\n",
    "                            char_labels[start] = \"B-Manner\"\n",
    "                            for i in range(start+1, end):\n",
    "                                char_labels[i] = \"I-Manner\"\n",
    "                            has_manner_fe = True\n",
    "            if not has_manner_fe:\n",
    "                continue\n",
    "\n",
    "\n",
    "            # Tokenize\n",
    "            tokenized = tokenizer(text, return_offsets_mapping=True, truncation=True, padding=\"max_length\", max_length=128)\n",
    "            input_ids = tokenized[\"input_ids\"]\n",
    "            attention_mask = tokenized[\"attention_mask\"]\n",
    "            offsets = tokenized[\"offset_mapping\"]\n",
    "\n",
    "            # Map character-level labels to token-level labels\n",
    "            token_labels = align_labels_with_tokens(text, char_labels, offsets)\n",
    "            label2id_binary = {\"O\": 0, \"B-Manner\": 1, \"I-Manner\": 2}  # Map both B-Manner to 1 and I to 2\n",
    "            # Pad remaining labels with -100 where attention mask is 0 (i.e., padding tokens)\n",
    "\n",
    "\n",
    "            label_ids = [label2id_binary.get(lab, 0) for lab in token_labels]\n",
    "            label_ids = [\n",
    "                label if mask == 1 else -100 \n",
    "                for label, mask in zip(label_ids, attention_mask)\n",
    "            ]\n",
    "            # Store tensors\n",
    "            input_ids_list.append(torch.tensor(input_ids))\n",
    "            attention_masks_list.append(torch.tensor(attention_mask))\n",
    "            labels_list.append(torch.tensor(label_ids))\n",
    "\n",
    "# Final dataset tensors\n",
    "input_ids_tensor = torch.stack(input_ids_list)\n",
    "attention_masks_tensor = torch.stack(attention_masks_list)\n",
    "labels_tensor = torch.stack(labels_list)\n",
    "\n",
    "print(\"Tensor shapes:\")\n",
    "print(\"Input IDs:\", input_ids_tensor.shape)\n",
    "print(\"Attention Masks:\", attention_masks_tensor.shape)\n",
    "print(\"Labels:\", labels_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "dataset = TensorDataset(input_ids_tensor, attention_masks_tensor, labels_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training and testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SubsetRandomSampler\n",
    "from torch.utils.data import random_split\n",
    "# Parameters\n",
    "batch_size = 5\n",
    "validation_split = 0.5\n",
    "\n",
    "train_size = int((1 - validation_split) * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),  # Shuffle the data\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Create DataLoader for validation (without shuffling)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    sampler=SubsetRandomSampler(range(len(val_dataset))),  # Don't shuffle validation data\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "class FrameElementClassifier(nn.Module):\n",
    "    def __init__(self, bert_model='bert-base-uncased'):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model)\n",
    "        #self.query_encoder = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size)\n",
    "        self.token_projection = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 3)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    #def forward(self, input_ids, attention_mask, role_ids, role_mask):\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Encode sentence\n",
    "        sentence_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        token_embeddings = sentence_outputs.last_hidden_state  # shape: (B, T, H)\n",
    "\n",
    "        # Project sentence tokens\n",
    "        token_embeddings = self.token_projection(token_embeddings)  # shape: (B, T, H)\n",
    "        logits = self.classifier(token_embeddings)\n",
    "\n",
    "        return logits  # Apply softmax for inference or use with CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "accuracies = []\n",
    "num_batches = 15\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FrameElementClassifier().to(device)\n",
    "#class_weights = torch.tensor([0.4, 0.6]).to(device)  # Make manner more important\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions_batch = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        print(i)\n",
    "        input_ids, attention_mask, target_index = [item.to(device) for item in batch]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        probs = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(probs.view(-1, 3), target_index.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "postprocessing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def fix_bio_predictions2(predictions):\n",
    "    corrected = []\n",
    "    batch_size, seq_len = predictions.shape\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        sentence = predictions[i].tolist()\n",
    "        sentence_corrected = sentence.copy()\n",
    "\n",
    "        for j in range(seq_len-1):\n",
    "            if sentence[j] == 2:  # I-Time\n",
    "                if j == 0:\n",
    "                    # Beginning of sequence, can't be I-Time\n",
    "                    sentence_corrected[j] = 0\n",
    "\n",
    "                elif sentence[j-1] == 0:\n",
    "                    # Look ahead to see if more 2's follow\n",
    "                    if sentence[j+1] == 2:\n",
    "                        if j > 2 and sentence[j-2] == 0:\n",
    "                            sentence_corrected[j-1] = 1\n",
    "                            sentence_corrected[j] = sentence[j]\n",
    "                        else:\n",
    "                            sentence_corrected[j-1] = 2\n",
    "                            sentence_corrected[j] = sentence[j]\n",
    "                    else: \n",
    "                        sentence_corrected[j] = 0\n",
    "                else:\n",
    "                    sentence_corrected[j] = sentence[j]\n",
    "            else:\n",
    "                sentence_corrected[j] = sentence[j]\n",
    "\n",
    "\n",
    "\n",
    "        corrected.append(sentence_corrected)\n",
    "\n",
    "    return torch.tensor(corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (O, B-Manner, I-Manner):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.97      0.98      0.98      1778\n",
      "    B-Manner       0.83      0.92      0.87        75\n",
      "    I-Manner       0.83      0.72      0.77       152\n",
      "\n",
      "    accuracy                           0.96      2005\n",
      "   macro avg       0.88      0.87      0.87      2005\n",
      "weighted avg       0.96      0.96      0.96      2005\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1744   12   22]\n",
      " [   5   69    1]\n",
      " [  40    2  110]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(val_dataloader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        input_ids, attention_mask, target_index = [item.to(device) for item in batch]\n",
    "\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        predicted_tokens = torch.argmax(logits, dim=-1)\n",
    "        fixed_predictions = fix_bio_predictions2(predicted_tokens)\n",
    "\n",
    "        mask = (target_index != -100)\n",
    "\n",
    "        all_true_labels.extend(target_index[mask].view(-1).cpu().numpy())\n",
    "        all_pred_labels.extend(predicted_tokens[mask].view(-1).cpu().numpy())\n",
    "\n",
    "# Report\n",
    "print(\"Classification Report (O, B-Manner, I-Manner):\")\n",
    "print(classification_report(all_true_labels, all_pred_labels, target_names=['O', 'B-Manner', 'I-Manner']))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix for Time FE Detection')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Accuracy: 1744/1778 = 0.9809\n",
      "B-Manner Accuracy: 69/75 = 0.9200\n",
      "I-Manner Accuracy: 110/152 = 0.7237\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "true_np = np.array(all_true_labels)\n",
    "pred_np = np.array(all_pred_labels)\n",
    "\n",
    "for label_id, label_name in enumerate(['O', 'B-Manner', 'I-Manner']):\n",
    "    total = np.sum(true_np == label_id)\n",
    "    correct = np.sum((true_np == label_id) & (pred_np == label_id))\n",
    "    print(f\"{label_name} Accuracy: {correct}/{total} = {correct/total:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation code to find the amount of full spans of FE we got correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "def evaluate_model_postprocessed(model, val_dataloader, device):\n",
    "    model.eval()\n",
    "    true_labels_all = []\n",
    "    pred_labels_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader):\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            raw_preds = torch.argmax(outputs, dim=-1)  # (B, T)\n",
    "            fixed_preds = fix_bio_predictions2(raw_preds)  # Apply post-processing\n",
    "\n",
    "            for label_seq, pred_seq, mask in zip(labels, fixed_preds, attention_mask):\n",
    "                # Remove padding and apply attention mask\n",
    "                true_seq = [label.item() for label, m in zip(label_seq, mask) if m == 1 and label != -100]\n",
    "                pred_seq = [pred.item() for pred, m in zip(pred_seq, mask) if m == 1]\n",
    "\n",
    "                true_labels_all.append(true_seq)\n",
    "                pred_labels_all.append(pred_seq[:len(true_seq)])\n",
    "\n",
    "    return evaluate_predictions(true_labels_all, pred_labels_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to extract spans and evaluate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_bio_spans(label_seq):\n",
    "    spans = []\n",
    "    start = None\n",
    "\n",
    "    for i, label in enumerate(label_seq):\n",
    "        if label == 1:  # B\n",
    "            if start is not None:\n",
    "                spans.append((start, i - 1))  # close previous span\n",
    "            start = i\n",
    "        elif label == 2:\n",
    "            if start is None:\n",
    "                # Ill-formed BIO (I without B) ‚Äî treat as beginning a new span\n",
    "                start = i\n",
    "        else:  # label == 0\n",
    "            if start is not None:\n",
    "                spans.append((start, i - 1))\n",
    "                start = None\n",
    "\n",
    "    if start is not None:\n",
    "        spans.append((start, len(label_seq) - 1))\n",
    "    \n",
    "    return spans\n",
    "\n",
    "def evaluate_predictions(true_labels_list, pred_labels_list):\n",
    "    strict_match = 0\n",
    "    partial_match = 0\n",
    "    total_spans = 0\n",
    "\n",
    "    for true_seq, pred_seq in zip(true_labels_list, pred_labels_list):\n",
    "        true_spans = extract_bio_spans(true_seq)\n",
    "        pred_spans = extract_bio_spans(pred_seq)\n",
    "        total_spans += len(true_spans)\n",
    "\n",
    "        for t_start, t_end in true_spans:\n",
    "            t_range = set(range(t_start, t_end + 1))\n",
    "            match_found = False\n",
    "            for p_start, p_end in pred_spans:\n",
    "                p_range = set(range(p_start, p_end + 1))\n",
    "                if t_range == p_range:\n",
    "                    strict_match += 1\n",
    "                    match_found = True\n",
    "                    break\n",
    "                elif t_range & p_range:\n",
    "                    match_found = True\n",
    "            if match_found:\n",
    "                partial_match += 1\n",
    "\n",
    "    return {\n",
    "        \"Total Time Elements\": total_spans,\n",
    "        \"Strict Matches\": strict_match,\n",
    "        \"Partial Matches\": partial_match,\n",
    "        \"Strict Accuracy\": strict_match / total_spans if total_spans > 0 else 0,\n",
    "        \"Partial Accuracy\": partial_match / total_spans if total_spans > 0 else 0\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 807/807 [02:58<00:00,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Post-Processed Evaluation Results:\n",
      "Total Time Elements: 4124\n",
      "Strict Matches: 3265\n",
      "Partial Matches: 3675\n",
      "Strict Accuracy: 0.792\n",
      "Partial Accuracy: 0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model_postprocessed(model, val_dataloader, device)\n",
    "\n",
    "print(\"üìä Post-Processed Evaluation Results:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v:.3f}\" if isinstance(v, float) else f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try some manual examples, no post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           O\n",
      "they            O\n",
      "had             O\n",
      "to              O\n",
      "trek            O\n",
      "on              B-Manner\n",
      "foot            I-Manner\n",
      "through         O\n",
      "the             O\n",
      "desert          O\n",
      ".               O\n",
      "[SEP]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           I-Manner\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           I-Manner\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# 2. Prepare a test sentence\n",
    "text = \"They had to trek on foot through the desert.\"\n",
    "\n",
    "# Tokenize with offsets to possibly map back later (optional here)\n",
    "encoding = tokenizer(text, return_tensors=\"pt\", return_offsets_mapping=True,\n",
    "                     truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "input_ids = encoding[\"input_ids\"]        # shape: (1, 128)\n",
    "attention_mask = encoding[\"attention_mask\"]\n",
    "offsets = encoding[\"offset_mapping\"]\n",
    "\n",
    "# 3. Pass through the model\n",
    "with torch.no_grad():\n",
    "    logits = model(input_ids, attention_mask)  # shape: (1, 128, 3)\n",
    "    predictions2 = torch.argmax(logits, dim=-1)  # shape: (1, 128)\n",
    "\n",
    "id2label = {0: \"O\", 1: \"B-Manner\", 2: \"I-Manner\"}\n",
    "predicted_tags2 = [id2label[i.item()] for i in predictions2[0]]\n",
    "\n",
    "# 5. Get back tokens for visualization (optional)\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "for tok, tag in zip(tokens, predicted_tags2):\n",
    "    print(f\"{tok:15} {tag}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST NEW POST PROCESSING TECNIQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def fix_bio_predictions3(predictions):\n",
    "    corrected = []\n",
    "    batch_size, seq_len = predictions.shape\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        sentence = predictions[i].tolist()\n",
    "        sentence_corrected = sentence.copy()\n",
    "\n",
    "        for j in range(seq_len):\n",
    "            tag = sentence[j]\n",
    "\n",
    "            if tag == 2:  # I-tag\n",
    "                if j == 0:\n",
    "                    # Can't start with I -> make it O\n",
    "                    sentence_corrected[j] = 0\n",
    "\n",
    "                elif sentence_corrected[j - 1] == 0:\n",
    "                    # Pattern: O I ...\n",
    "                    # Check if a run of I-tags follows\n",
    "                    run_length = 1\n",
    "                    k = j + 1\n",
    "                    while k < seq_len and sentence[k] == 2:\n",
    "                        run_length += 1\n",
    "                        k += 1\n",
    "\n",
    "                    if run_length >= 1:\n",
    "                        # Change the O (at j-1) to B\n",
    "                        sentence_corrected[j - 1] = 1\n",
    "                    else:\n",
    "                        # Lone I -> make it O\n",
    "                        sentence_corrected[j] = 0\n",
    "\n",
    "        corrected.append(sentence_corrected)\n",
    "\n",
    "    return torch.tensor(corrected, device=predictions.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "def evaluate_model_postprocessed2(model, val_dataloader, device):\n",
    "    model.eval()\n",
    "    true_labels_all = []\n",
    "    pred_labels_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader):\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            raw_preds = torch.argmax(outputs, dim=-1)  # (B, T)\n",
    "            fixed_preds = fix_bio_predictions3(raw_preds)  # Apply post-processing\n",
    "\n",
    "            for label_seq, pred_seq, mask in zip(labels, fixed_preds, attention_mask):\n",
    "                # Remove padding and apply attention mask\n",
    "                true_seq = [label.item() for label, m in zip(label_seq, mask) if m == 1 and label != -100]\n",
    "                pred_seq = [pred.item() for pred, m in zip(pred_seq, mask) if m == 1]\n",
    "\n",
    "                true_labels_all.append(true_seq)\n",
    "                pred_labels_all.append(pred_seq[:len(true_seq)])\n",
    "\n",
    "    return evaluate_predictions(true_labels_all, pred_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 807/807 [03:09<00:00,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Post-Processed Evaluation Results:\n",
      "Total Time Elements: 4124\n",
      "Strict Matches: 3286\n",
      "Partial Matches: 3767\n",
      "Strict Accuracy: 0.797\n",
      "Partial Accuracy: 0.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results2 = evaluate_model_postprocessed2(model, val_dataloader, device)\n",
    "\n",
    "print(\"üìä Post-Processed Evaluation Results:\")\n",
    "for k, v in results2.items():\n",
    "    print(f\"{k}: {v:.3f}\" if isinstance(v, float) else f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slight increase in strict accuracy with second post processing function (0.694->0.698)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           O\n",
      "he              O\n",
      "cleaned         O\n",
      "with            B-Manner\n",
      "a               I-Manner\n",
      "rag             I-Manner\n",
      "[SEP]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# 2. Prepare a test sentence\n",
    "text = \"He cleaned with a rag\"\n",
    "\n",
    "# Tokenize with offsets to possibly map back later (optional here)\n",
    "encoding = tokenizer(text, return_tensors=\"pt\", return_offsets_mapping=True,\n",
    "                     truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "input_ids = encoding[\"input_ids\"]        # shape: (1, 128)\n",
    "attention_mask = encoding[\"attention_mask\"]\n",
    "offsets = encoding[\"offset_mapping\"]\n",
    "\n",
    "# 3. Pass through the model\n",
    "with torch.no_grad():\n",
    "    logits = model(input_ids, attention_mask)  # shape: (1, 128, 3)\n",
    "    predictions2 = torch.argmax(logits, dim=-1)  # shape: (1, 128)\n",
    "    fixed_preds = fix_bio_predictions3(predictions2)\n",
    "\n",
    "id2label = {0: \"O\", 1: \"B-Manner\", 2: \"I-Manner\"}\n",
    "predicted_tags2 = [id2label[i.item()] for i in fixed_preds[0]]\n",
    "\n",
    "# 5. Get back tokens for visualization (optional)\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "for tok, tag in zip(tokens, predicted_tags2):\n",
    "    print(f\"{tok:15} {tag}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
