{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook metadata fixed! You can now commit to GitHub.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#from google.colab import drive\n",
    "\n",
    "# Get the notebook's filename (usually matches the GitHub repo name)\n",
    "!ls *.ipynb\n",
    "notebook_name = \"NLPProject.ipynb\"  # ‚Üê Replace with your filename\n",
    "\n",
    "# Load and fix the notebook\n",
    "with open(notebook_name, 'r') as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "# Option A: Remove widgets metadata completely (recommended)\n",
    "if 'metadata' in nb and 'widgets' in nb['metadata']:\n",
    "    del nb['metadata']['widgets']\n",
    "\n",
    "# Option B: Or add the missing state key\n",
    "# if 'metadata' in nb and 'widgets' in nb['metadata']:\n",
    "#     nb['metadata']['widgets']['state'] = {}\n",
    "\n",
    "# Save the fixed version\n",
    "with open(notebook_name, 'w') as f:\n",
    "    json.dump(nb, f)\n",
    "\n",
    "print(\"Notebook metadata fixed! You can now commit to GitHub.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package framenet_v17 to\n",
      "[nltk_data]     C:\\Users\\ogboi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package framenet_v17 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from operator import itemgetter\n",
    "import nltk\n",
    "from nltk.corpus import framenet as fn\n",
    "from nltk.corpus.reader.framenet import PrettyList\n",
    "nltk.download('framenet_v17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Element: Time, Sample Sentences: 8170\n",
      "Frame Element: Manner, Sample Sentences: 7612\n",
      "Frame Element: Place, Sample Sentences: 7037\n",
      "Frame Element: Degree, Sample Sentences: 7012\n",
      "Frame Element: Means, Sample Sentences: 5045\n",
      "Frame Element: Explanation, Sample Sentences: 4539\n",
      "Frame Element: Depictive, Sample Sentences: 4091\n",
      "Frame Element: Purpose, Sample Sentences: 4091\n",
      "Frame Element: Circumstances, Sample Sentences: 3219\n",
      "Frame Element: Duration, Sample Sentences: 3120\n"
     ]
    }
   ],
   "source": [
    "frame_element_counts = {}\n",
    "#for each frame, loops through all frame elements\n",
    "for frame in fn.frames():\n",
    "    frame_name = frame.name\n",
    "\n",
    "    for fe_name, fe in frame.FE.items():\n",
    "\n",
    "        sample_sentences = frame.lexUnit\n",
    "        num_sentences = len(sample_sentences)\n",
    "\n",
    "        # Store the count of sentences for each frame element\n",
    "        if fe_name in frame_element_counts:\n",
    "            frame_element_counts[fe_name] += num_sentences  # Add the new count to the existing one\n",
    "        else:\n",
    "            frame_element_counts[fe_name] = num_sentences\n",
    "\n",
    "sorted_frame_elements = sorted(frame_element_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "for fe_name, count in sorted_frame_elements[:10]:\n",
    "    print(f\"Frame Element: {fe_name}, Sample Sentences: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_with_time_ex = {}\n",
    "for f in fn.frames():\n",
    "    for x in f.FE:\n",
    "        if x == \"Time\":\n",
    "            frames_with_time_ex[f.name] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(text, char_labels, offsets):\n",
    "    token_labels = []\n",
    "    for (token_start, token_end) in offsets:\n",
    "        # For special tokens like [CLS] and [SEP], offset is usually (0,0)\n",
    "        if token_start == token_end:\n",
    "            token_labels.append(\"O\")\n",
    "        else:\n",
    "            # If any character in the token is marked as Time,\n",
    "            # decide on a label for the entire token.\n",
    "            token_tag = \"O\"\n",
    "            for pos in range(token_start, token_end):\n",
    "                if pos < len(char_labels) and char_labels[pos] != \"O\":\n",
    "                    token_tag = char_labels[pos]\n",
    "                    break\n",
    "            token_labels.append(token_tag)\n",
    "    return token_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shapes:\n",
      "Input IDs: torch.Size([9013, 128])\n",
      "Attention Masks: torch.Size([9013, 128])\n",
      "Labels: torch.Size([9013, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from nltk.corpus import framenet as fn\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Map BIO tags to IDs\n",
    "label2id = {\"O\": 0, \"B-Time\": 1, \"I-Time\": 2}\n",
    "input_ids_list = []\n",
    "attention_masks_list = []\n",
    "labels_list = []\n",
    "\n",
    "# Find frames that include \"Time\" as a frame element\n",
    "\n",
    "for name, frame in frames_with_time_ex.items():\n",
    "    # Print the frame name for reference\n",
    "    for lu in frame.lexUnit.values():\n",
    "        #print(f\"\\nLexical Unit: {lu['name']}\")\n",
    "        lu_data = fn.lu(lu['ID'])\n",
    "        for ex in lu_data['exemplars']:\n",
    "            text = ex['text']\n",
    "            char_labels = [\"O\"] * len(text)\n",
    "            has_time_fe = False\n",
    "\n",
    "            for fe in ex['FE']:\n",
    "                for i in fe:\n",
    "                    if i[2] == \"Time\":\n",
    "                        start, end = i[0], i[1]\n",
    "                        if start < end:\n",
    "                            char_labels[start] = \"B-Time\"\n",
    "                            for i in range(start+1, end):\n",
    "                                char_labels[i] = \"I-Time\"\n",
    "                            has_time_fe = True\n",
    "            if not has_time_fe:\n",
    "                continue\n",
    "\n",
    "\n",
    "            # Tokenize\n",
    "            tokenized = tokenizer(text, return_offsets_mapping=True, truncation=True, padding=\"max_length\", max_length=128)\n",
    "            input_ids = tokenized[\"input_ids\"]\n",
    "            attention_mask = tokenized[\"attention_mask\"]\n",
    "            offsets = tokenized[\"offset_mapping\"]\n",
    "\n",
    "            # Map character-level labels to token-level labels\n",
    "            token_labels = align_labels_with_tokens(text, char_labels, offsets)\n",
    "            label2id_binary = {\"O\": 0, \"B-Time\": 1, \"I-Time\": 1}  # Map both B-Time and I-Time to 1\n",
    "            # Pad remaining labels with -100 where attention mask is 0 (i.e., padding tokens)\n",
    "\n",
    "\n",
    "            label_ids = [label2id_binary.get(lab, 0) for lab in token_labels]\n",
    "            label_ids = [\n",
    "                label if mask == 1 else -100 \n",
    "                for label, mask in zip(label_ids, attention_mask)\n",
    "            ]\n",
    "            # Store tensors\n",
    "            input_ids_list.append(torch.tensor(input_ids))\n",
    "            attention_masks_list.append(torch.tensor(attention_mask))\n",
    "            labels_list.append(torch.tensor(label_ids))\n",
    "\n",
    "# Final dataset tensors\n",
    "input_ids_tensor = torch.stack(input_ids_list)\n",
    "attention_masks_tensor = torch.stack(attention_masks_list)\n",
    "labels_tensor = torch.stack(labels_list)\n",
    "\n",
    "print(\"Tensor shapes:\")\n",
    "print(\"Input IDs:\", input_ids_tensor.shape)\n",
    "print(\"Attention Masks:\", attention_masks_tensor.shape)\n",
    "print(\"Labels:\", labels_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: when\n"
     ]
    }
   ],
   "source": [
    "indices = (labels_tensor == 1).nonzero(as_tuple=False)\n",
    "sample_idx, token_idx = indices[0].tolist()\n",
    "token_id = input_ids_tensor[sample_idx][token_idx]\n",
    "token = tokenizer.convert_ids_to_tokens([token_id])[0]\n",
    "print(f\"Token: {token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['[CLS]', 'she', 'had', 'seen', 'no', 'reason', 'to', 'abandon', 'it', 'when', 'she', 'came', 'to', 'med', '##ew', '##ich', 'two', 'years', 'ago', ',', 'even', 'though', 'she', 'might', 'now', 'have', 'been', 'able', 'to', 'afford', 'a', 'car', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(input_ids_tensor[sample_idx])\n",
    "print(\"Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           -> 0\n",
      "she             -> 0\n",
      "had             -> 0\n",
      "seen            -> 0\n",
      "no              -> 0\n",
      "reason          -> 0\n",
      "to              -> 0\n",
      "abandon         -> 0\n",
      "it              -> 0\n",
      "when            -> 1\n",
      "she             -> 1\n",
      "came            -> 1\n",
      "to              -> 1\n",
      "med             -> 1\n",
      "##ew            -> 1\n",
      "##ich           -> 1\n",
      "two             -> 1\n",
      "years           -> 1\n",
      "ago             -> 1\n",
      ",               -> 0\n",
      "even            -> 0\n",
      "though          -> 0\n",
      "she             -> 0\n",
      "might           -> 0\n",
      "now             -> 0\n",
      "have            -> 0\n",
      "been            -> 0\n",
      "able            -> 0\n",
      "to              -> 0\n",
      "afford          -> 0\n",
      "a               -> 0\n",
      "car             -> 0\n",
      ".               -> 0\n",
      "[SEP]           -> 0\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n",
      "[PAD]           -> -100\n"
     ]
    }
   ],
   "source": [
    "labels = labels_tensor[sample_idx]\n",
    "for tok, label in zip(tokens, labels):\n",
    "    print(f\"{tok:15} -> {label.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "dataset = TensorDataset(input_ids_tensor, attention_masks_tensor, labels_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SubsetRandomSampler\n",
    "from torch.utils.data import random_split\n",
    "# Parameters\n",
    "batch_size = 5\n",
    "validation_split = 0.5\n",
    "\n",
    "train_size = int((1 - validation_split) * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),  # Shuffle the data\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Create DataLoader for validation (without shuffling)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    sampler=SubsetRandomSampler(range(len(val_dataset))),  # Don't shuffle validation data\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "class FrameElementClassifier(nn.Module):\n",
    "    def __init__(self, bert_model='bert-base-uncased'):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model)\n",
    "        #self.query_encoder = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size)\n",
    "        self.token_projection = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    #def forward(self, input_ids, attention_mask, role_ids, role_mask):\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Encode sentence\n",
    "        sentence_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        token_embeddings = sentence_outputs.last_hidden_state  # shape: (B, T, H)\n",
    "        \"\"\"\n",
    "        # Encode role label (like \"Time\" or \"Manner\")\n",
    "        role_output = self.bert(input_ids=role_ids, attention_mask=role_mask)\n",
    "        role_embedding = role_output.last_hidden_state[:, 0, :]  # [CLS] token: shape (B, H)\n",
    "        role_embedding = self.query_encoder(role_embedding)  # shape: (B, H)\n",
    "\"\"\"\n",
    "        # Project sentence tokens\n",
    "        token_embeddings = self.token_projection(token_embeddings)  # shape: (B, T, H)\n",
    "        logits = self.classifier(token_embeddings)\n",
    "        # Compute dot product between role embedding and each token\n",
    "        #role_embedding = role_embedding.unsqueeze(2)  # (B, H, 1)\n",
    "        #scores = torch.bmm(token_embeddings, role_embedding).squeeze(-1)  # shape: (B, T)\n",
    "\n",
    "        # Optionally apply attention mask\n",
    "        #scores = scores.masked_fill(attention_mask == 0, -1e9)\n",
    "        #probs = torch.softmax(logits, dim=-1)\n",
    "        #logits = self.classifier(token_embeddings)\n",
    "        return logits  # Apply softmax for inference or use with CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run for a few more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "accuracies = []\n",
    "num_batches = 15\n",
    "model = FrameElementClassifier()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_weights = torch.tensor([0.4, 0.6]).to(device)  # Make Time more important\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights, ignore_index=-100)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions_batch = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        print(i)\n",
    "        input_ids, attention_mask, target_index = [item.to(device) for item in batch]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        probs = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(probs.view(-1, 2), target_index.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time FE Recall: 0.8524 (231/271)\n",
      "Confusion Matrix (for 'Time' class prediction):\n",
      "[[8366  963]\n",
      " [  40  231]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "true_time_total = 0\n",
    "true_time_correct = 0\n",
    "\n",
    "# For confusion matrix\n",
    "all_true_binary = []\n",
    "all_pred_binary = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(val_dataloader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        input_ids, attention_mask, target_index = [item.to(device) for item in batch]\n",
    "\n",
    "        probs = model(input_ids, attention_mask)\n",
    "        probs_softmax = torch.softmax(probs, dim=-1)\n",
    "        predicted_tokens = torch.argmax(probs_softmax, dim=-1)\n",
    "\n",
    "        # Binary labels: 1 for \"Time\", 0 for everything else\n",
    "        is_time_token = (target_index == 1)\n",
    "        predicted_time_token = (predicted_tokens == 1)\n",
    "\n",
    "        correct_time_preds = predicted_time_token & is_time_token\n",
    "\n",
    "        true_time_total += is_time_token.sum().item()\n",
    "        true_time_correct += correct_time_preds.sum().item()\n",
    "\n",
    "        # Flatten and convert to binary 0/1\n",
    "        all_true_binary.extend(is_time_token.view(-1).cpu().numpy())\n",
    "        all_pred_binary.extend(predicted_time_token.view(-1).cpu().numpy())\n",
    "\n",
    "if true_time_total > 0:\n",
    "    time_recall = true_time_correct / true_time_total\n",
    "    print(f\"Time FE Recall: {time_recall:.4f} ({true_time_correct}/{true_time_total})\")\n",
    "else:\n",
    "    print(\"No Time FEs found in validation set.\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(all_true_binary, all_pred_binary)\n",
    "print(\"Confusion Matrix (for 'Time' class prediction):\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix for Time FE Detection')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix: \n",
    "\n",
    "\n",
    "\t              | Predicted: Not Time (0) |\tPredicted: Time (1)\n",
    "\n",
    "\n",
    "                  Actual: Not Time (0) | 8442\t              | 889\n",
    "\n",
    "\n",
    "                   Actual: Time (1)  |\t14\t                  |255\n",
    "\n",
    "Model on average is good at finding time frame elements, though its not perfectly precise ( a lot of not time elements are still be declared as time elements )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time FE Recall: 0.8251 (217/263)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "true_time_total = 0\n",
    "true_time_correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(val_dataloader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        input_ids, attention_mask, target_index = [item.to(device) for item in batch]\n",
    "\n",
    "        probs = model(input_ids, attention_mask)\n",
    "        probs_softmax = torch.softmax(probs, dim=-1)\n",
    "        predicted_tokens = torch.argmax(probs_softmax, dim=-1)\n",
    "\n",
    "        # Only count tokens that were labeled as \"Time\" (class 1) in the ground truth\n",
    "        is_time_token = (target_index == 1)\n",
    "        correct_time_preds = (predicted_tokens == 1) & is_time_token\n",
    "\n",
    "        true_time_total += is_time_token.sum().item()\n",
    "        true_time_correct += correct_time_preds.sum().item()\n",
    "\n",
    "if true_time_total > 0:\n",
    "    time_recall = true_time_correct / true_time_total\n",
    "    print(f\"Time FE Recall: {time_recall:.4f} ({true_time_correct}/{true_time_total})\")\n",
    "else:\n",
    "    print(\"No Time FEs found in validation set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 1 ---\n",
      "Predicted : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True      : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "--- Example 2 ---\n",
      "Predicted : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      "True      : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "--- Example 3 ---\n",
      "Predicted : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "True      : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0]\n",
      "\n",
      "--- Example 4 ---\n",
      "Predicted : [0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True      : [0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "--- Example 5 ---\n",
      "Predicted : [0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True      : [0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_printed = 0\n",
    "max_to_print = 5  # Adjust how many examples you want to print\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(val_dataloader):\n",
    "        if i >= num_batches or num_printed >= max_to_print:\n",
    "            break\n",
    "        input_ids, attention_mask, target_index = [item.to(device) for item in batch]\n",
    "\n",
    "        probs = model(input_ids, attention_mask)\n",
    "        probs_softmax = torch.softmax(probs, dim=-1)\n",
    "        predicted_tokens = torch.argmax(probs_softmax, dim=-1)\n",
    "\n",
    "        # Loop through each sentence in the batch\n",
    "        for b in range(input_ids.size(0)):\n",
    "            mask = target_index[b] != -100\n",
    "            true_labels = target_index[b][mask].cpu().numpy()\n",
    "            pred_labels = predicted_tokens[b][mask].cpu().numpy()\n",
    "\n",
    "            print(f\"\\n--- Example {num_printed + 1} ---\")\n",
    "            print(\"Predicted :\", pred_labels)\n",
    "            print(\"True      :\", true_labels)\n",
    "\n",
    "            num_printed += 1\n",
    "            if num_printed >= max_to_print:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Sentence 1:\n",
      "   Text: [CLS] last september, germany froze all development aid to vietnam and said hanoi was violating international law by not taking back its citizens. [SEP]\n",
      "   Tokens: ['[CLS]', 'last', 'september', ',', 'germany', 'froze', 'all', 'development', 'aid', 'to', 'vietnam', 'and', 'said', 'hanoi', 'was', 'violating', 'international', 'law', 'by', 'not', 'taking', 'back', 'its', 'citizens', '.', '[SEP]']\n",
      "   True Labels:     [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "   Predicted Labels:[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "   Comparison:\n",
      "     [CLS]           | True: 0 | Pred: 0 ‚úÖ\n",
      "     last            | True: 1 | Pred: 1 ‚úÖ\n",
      "     september       | True: 1 | Pred: 1 ‚úÖ\n",
      "     ,               | True: 0 | Pred: 0 ‚úÖ\n",
      "     germany         | True: 0 | Pred: 0 ‚úÖ\n",
      "     froze           | True: 0 | Pred: 0 ‚úÖ\n",
      "     all             | True: 0 | Pred: 0 ‚úÖ\n",
      "     development     | True: 0 | Pred: 0 ‚úÖ\n",
      "     aid             | True: 0 | Pred: 0 ‚úÖ\n",
      "     to              | True: 0 | Pred: 0 ‚úÖ\n",
      "     vietnam         | True: 0 | Pred: 0 ‚úÖ\n",
      "     and             | True: 0 | Pred: 0 ‚úÖ\n",
      "     said            | True: 0 | Pred: 0 ‚úÖ\n",
      "     hanoi           | True: 0 | Pred: 0 ‚úÖ\n",
      "     was             | True: 0 | Pred: 0 ‚úÖ\n",
      "     violating       | True: 0 | Pred: 0 ‚úÖ\n",
      "     international   | True: 0 | Pred: 0 ‚úÖ\n",
      "     law             | True: 0 | Pred: 0 ‚úÖ\n",
      "     by              | True: 0 | Pred: 0 ‚úÖ\n",
      "     not             | True: 0 | Pred: 0 ‚úÖ\n",
      "     taking          | True: 0 | Pred: 0 ‚úÖ\n",
      "     back            | True: 0 | Pred: 0 ‚úÖ\n",
      "     its             | True: 0 | Pred: 0 ‚úÖ\n",
      "     citizens        | True: 0 | Pred: 0 ‚úÖ\n",
      "     .               | True: 0 | Pred: 0 ‚úÖ\n",
      "     [SEP]           | True: 0 | Pred: 0 ‚úÖ\n",
      "\n",
      "üîπ Sentence 2:\n",
      "   Text: [CLS] shanahan previously coached for seven seasons with the broncos, mostly as offensive coordinator. [SEP]\n",
      "   Tokens: ['[CLS]', 'shan', '##aha', '##n', 'previously', 'coached', 'for', 'seven', 'seasons', 'with', 'the', 'broncos', ',', 'mostly', 'as', 'offensive', 'coordinator', '.', '[SEP]']\n",
      "   True Labels:     [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "   Predicted Labels:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "   Comparison:\n",
      "     [CLS]           | True: 0 | Pred: 0 ‚úÖ\n",
      "     shan            | True: 0 | Pred: 0 ‚úÖ\n",
      "     ##aha           | True: 0 | Pred: 0 ‚úÖ\n",
      "     ##n             | True: 0 | Pred: 0 ‚úÖ\n",
      "     previously      | True: 1 | Pred: 0 ‚ùå\n",
      "     coached         | True: 0 | Pred: 0 ‚úÖ\n",
      "     for             | True: 0 | Pred: 0 ‚úÖ\n",
      "     seven           | True: 0 | Pred: 0 ‚úÖ\n",
      "     seasons         | True: 0 | Pred: 0 ‚úÖ\n",
      "     with            | True: 0 | Pred: 0 ‚úÖ\n",
      "     the             | True: 0 | Pred: 0 ‚úÖ\n",
      "     broncos         | True: 0 | Pred: 0 ‚úÖ\n",
      "     ,               | True: 0 | Pred: 0 ‚úÖ\n",
      "     mostly          | True: 0 | Pred: 0 ‚úÖ\n",
      "     as              | True: 0 | Pred: 0 ‚úÖ\n",
      "     offensive       | True: 0 | Pred: 0 ‚úÖ\n",
      "     coordinator     | True: 0 | Pred: 0 ‚úÖ\n",
      "     .               | True: 0 | Pred: 0 ‚úÖ\n",
      "     [SEP]           | True: 0 | Pred: 0 ‚úÖ\n",
      "\n",
      "üîπ Sentence 3:\n",
      "   Text: [CLS] a number of mourners were quite abusive after the service and if i had not found the funeral so moving i would of asked one or two to step into the vestry. [SEP]\n",
      "   Tokens: ['[CLS]', 'a', 'number', 'of', 'mo', '##urne', '##rs', 'were', 'quite', 'abusive', 'after', 'the', 'service', 'and', 'if', 'i', 'had', 'not', 'found', 'the', 'funeral', 'so', 'moving', 'i', 'would', 'of', 'asked', 'one', 'or', 'two', 'to', 'step', 'into', 'the', 'vest', '##ry', '.', '[SEP]']\n",
      "   True Labels:     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "   Predicted Labels:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "   Comparison:\n",
      "     [CLS]           | True: 0 | Pred: 0 ‚úÖ\n",
      "     a               | True: 0 | Pred: 0 ‚úÖ\n",
      "     number          | True: 0 | Pred: 0 ‚úÖ\n",
      "     of              | True: 0 | Pred: 0 ‚úÖ\n",
      "     mo              | True: 0 | Pred: 0 ‚úÖ\n",
      "     ##urne          | True: 0 | Pred: 0 ‚úÖ\n",
      "     ##rs            | True: 0 | Pred: 0 ‚úÖ\n",
      "     were            | True: 0 | Pred: 0 ‚úÖ\n",
      "     quite           | True: 0 | Pred: 0 ‚úÖ\n",
      "     abusive         | True: 0 | Pred: 0 ‚úÖ\n",
      "     after           | True: 1 | Pred: 1 ‚úÖ\n",
      "     the             | True: 1 | Pred: 1 ‚úÖ\n",
      "     service         | True: 1 | Pred: 1 ‚úÖ\n",
      "     and             | True: 0 | Pred: 0 ‚úÖ\n",
      "     if              | True: 0 | Pred: 0 ‚úÖ\n",
      "     i               | True: 0 | Pred: 0 ‚úÖ\n",
      "     had             | True: 0 | Pred: 0 ‚úÖ\n",
      "     not             | True: 0 | Pred: 0 ‚úÖ\n",
      "     found           | True: 0 | Pred: 0 ‚úÖ\n",
      "     the             | True: 0 | Pred: 0 ‚úÖ\n",
      "     funeral         | True: 0 | Pred: 0 ‚úÖ\n",
      "     so              | True: 0 | Pred: 0 ‚úÖ\n",
      "     moving          | True: 0 | Pred: 0 ‚úÖ\n",
      "     i               | True: 0 | Pred: 0 ‚úÖ\n",
      "     would           | True: 0 | Pred: 0 ‚úÖ\n",
      "     of              | True: 0 | Pred: 0 ‚úÖ\n",
      "     asked           | True: 0 | Pred: 0 ‚úÖ\n",
      "     one             | True: 0 | Pred: 0 ‚úÖ\n",
      "     or              | True: 0 | Pred: 0 ‚úÖ\n",
      "     two             | True: 0 | Pred: 0 ‚úÖ\n",
      "     to              | True: 0 | Pred: 0 ‚úÖ\n",
      "     step            | True: 0 | Pred: 0 ‚úÖ\n",
      "     into            | True: 0 | Pred: 0 ‚úÖ\n",
      "     the             | True: 0 | Pred: 0 ‚úÖ\n",
      "     vest            | True: 0 | Pred: 0 ‚úÖ\n",
      "     ##ry            | True: 0 | Pred: 0 ‚úÖ\n",
      "     .               | True: 0 | Pred: 0 ‚úÖ\n",
      "     [SEP]           | True: 0 | Pred: 0 ‚úÖ\n",
      "\n",
      "üîπ Sentence 4:\n",
      "   Text: [CLS] at the national colin blakely and paul schofield played the lead in 1968 and 1977 respectively, and the rsc mounted the major production of the eighties with richard griffiths and miles anderson. [SEP]\n",
      "   Tokens: ['[CLS]', 'at', 'the', 'national', 'colin', 'blake', '##ly', 'and', 'paul', 'sc', '##hof', '##ield', 'played', 'the', 'lead', 'in', '1968', 'and', '1977', 'respectively', ',', 'and', 'the', 'rs', '##c', 'mounted', 'the', 'major', 'production', 'of', 'the', 'eighties', 'with', 'richard', 'griffiths', 'and', 'miles', 'anderson', '.', '[SEP]']\n",
      "   True Labels:     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "   Predicted Labels:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "   Comparison:\n",
      "     [CLS]           | True: 0 | Pred: 0 ‚úÖ\n",
      "     at              | True: 0 | Pred: 0 ‚úÖ\n",
      "     the             | True: 0 | Pred: 0 ‚úÖ\n",
      "     national        | True: 0 | Pred: 0 ‚úÖ\n",
      "     colin           | True: 0 | Pred: 0 ‚úÖ\n",
      "     blake           | True: 0 | Pred: 0 ‚úÖ\n",
      "     ##ly            | True: 0 | Pred: 0 ‚úÖ\n",
      "     and             | True: 0 | Pred: 0 ‚úÖ\n",
      "     paul            | True: 0 | Pred: 0 ‚úÖ\n",
      "     sc              | True: 0 | Pred: 0 ‚úÖ\n",
      "     ##hof           | True: 0 | Pred: 0 ‚úÖ\n",
      "     ##ield          | True: 0 | Pred: 0 ‚úÖ\n",
      "     played          | True: 0 | Pred: 0 ‚úÖ\n",
      "     the             | True: 0 | Pred: 0 ‚úÖ\n",
      "     lead            | True: 0 | Pred: 0 ‚úÖ\n",
      "     in              | True: 1 | Pred: 1 ‚úÖ\n",
      "     1968            | True: 1 | Pred: 1 ‚úÖ\n",
      "     and             | True: 1 | Pred: 0 ‚ùå\n",
      "     1977            | True: 1 | Pred: 1 ‚úÖ\n",
      "     respectively    | True: 1 | Pred: 0 ‚ùå\n",
      "     ,               | True: 0 | Pred: 0 ‚úÖ\n",
      "     and             | True: 0 | Pred: 0 ‚úÖ\n",
      "     the             | True: 0 | Pred: 0 ‚úÖ\n",
      "     rs              | True: 0 | Pred: 0 ‚úÖ\n",
      "     ##c             | True: 0 | Pred: 0 ‚úÖ\n",
      "     mounted         | True: 0 | Pred: 0 ‚úÖ\n",
      "     the             | True: 0 | Pred: 0 ‚úÖ\n",
      "     major           | True: 0 | Pred: 0 ‚úÖ\n",
      "     production      | True: 0 | Pred: 0 ‚úÖ\n",
      "     of              | True: 0 | Pred: 1 ‚ùå\n",
      "     the             | True: 0 | Pred: 0 ‚úÖ\n",
      "     eighties        | True: 0 | Pred: 0 ‚úÖ\n",
      "     with            | True: 0 | Pred: 0 ‚úÖ\n",
      "     richard         | True: 0 | Pred: 0 ‚úÖ\n",
      "     griffiths       | True: 0 | Pred: 0 ‚úÖ\n",
      "     and             | True: 0 | Pred: 0 ‚úÖ\n",
      "     miles           | True: 0 | Pred: 0 ‚úÖ\n",
      "     anderson        | True: 0 | Pred: 0 ‚úÖ\n",
      "     .               | True: 0 | Pred: 0 ‚úÖ\n",
      "     [SEP]           | True: 0 | Pred: 0 ‚úÖ\n",
      "\n",
      "üîπ Sentence 5:\n",
      "   Text: [CLS] in the wake of this tremendous natural upheaval, the aegean islands next came under the influence of the mycenaeans ( at around 1300 b. c. ), who had a base in the peloponnese region of the greek mainland. [SEP]\n",
      "   Tokens: ['[CLS]', 'in', 'the', 'wake', 'of', 'this', 'tremendous', 'natural', 'up', '##hea', '##val', ',', 'the', 'aegean', 'islands', 'next', 'came', 'under', 'the', 'influence', 'of', 'the', 'my', '##cen', '##aea', '##ns', '(', 'at', 'around', '1300', 'b', '.', 'c', '.', ')', ',', 'who', 'had', 'a', 'base', 'in', 'the', 'pe', '##lo', '##pon', '##nese', 'region', 'of', 'the', 'greek', 'mainland', '.', '[SEP]']\n",
      "   True Labels:     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "   Predicted Labels:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "   Comparison:\n",
      "     [CLS]           | True: 0 | Pred: 0 ‚úÖ\n",
      "     in              | True: 0 | Pred: 0 ‚úÖ\n",
      "     the             | True: 0 | Pred: 0 ‚úÖ\n",
      "     wake            | True: 0 | Pred: 0 ‚úÖ\n",
      "     of              | True: 0 | Pred: 0 ‚úÖ\n",
      "     this            | True: 0 | Pred: 0 ‚úÖ\n",
      "     tremendous      | True: 0 | Pred: 0 ‚úÖ\n",
      "     natural         | True: 0 | Pred: 0 ‚úÖ\n",
      "     up              | True: 0 | Pred: 0 ‚úÖ\n",
      "     ##hea           | True: 0 | Pred: 0 ‚úÖ\n",
      "     ##val           | True: 0 | Pred: 0 ‚úÖ\n",
      "     ,               | True: 0 | Pred: 0 ‚úÖ\n",
      "     the             | True: 0 | Pred: 0 ‚úÖ\n",
      "     aegean          | True: 0 | Pred: 0 ‚úÖ\n",
      "     islands         | True: 0 | Pred: 0 ‚úÖ\n",
      "     next            | True: 0 | Pred: 0 ‚úÖ\n",
      "     came            | True: 0 | Pred: 0 ‚úÖ\n",
      "     under           | True: 0 | Pred: 0 ‚úÖ\n",
      "     the             | True: 0 | Pred: 0 ‚úÖ\n",
      "     influence       | True: 0 | Pred: 0 ‚úÖ\n",
      "     of              | True: 0 | Pred: 0 ‚úÖ\n",
      "     the             | True: 0 | Pred: 0 ‚úÖ\n",
      "     my              | True: 0 | Pred: 0 ‚úÖ\n",
      "     ##cen           | True: 0 | Pred: 0 ‚úÖ\n",
      "     ##aea           | True: 0 | Pred: 0 ‚úÖ\n",
      "     ##ns            | True: 0 | Pred: 0 ‚úÖ\n",
      "     (               | True: 0 | Pred: 0 ‚úÖ\n",
      "     at              | True: 1 | Pred: 1 ‚úÖ\n",
      "     around          | True: 1 | Pred: 1 ‚úÖ\n",
      "     1300            | True: 1 | Pred: 1 ‚úÖ\n",
      "     b               | True: 1 | Pred: 1 ‚úÖ\n",
      "     .               | True: 1 | Pred: 1 ‚úÖ\n",
      "     c               | True: 1 | Pred: 1 ‚úÖ\n",
      "     .               | True: 1 | Pred: 1 ‚úÖ\n",
      "     )               | True: 0 | Pred: 0 ‚úÖ\n",
      "     ,               | True: 0 | Pred: 0 ‚úÖ\n",
      "     who             | True: 0 | Pred: 0 ‚úÖ\n",
      "     had             | True: 0 | Pred: 0 ‚úÖ\n",
      "     a               | True: 0 | Pred: 0 ‚úÖ\n",
      "     base            | True: 0 | Pred: 0 ‚úÖ\n",
      "     in              | True: 0 | Pred: 0 ‚úÖ\n",
      "     the             | True: 0 | Pred: 0 ‚úÖ\n",
      "     pe              | True: 0 | Pred: 0 ‚úÖ\n",
      "     ##lo            | True: 0 | Pred: 0 ‚úÖ\n",
      "     ##pon           | True: 0 | Pred: 0 ‚úÖ\n",
      "     ##nese          | True: 0 | Pred: 0 ‚úÖ\n",
      "     region          | True: 0 | Pred: 0 ‚úÖ\n",
      "     of              | True: 0 | Pred: 0 ‚úÖ\n",
      "     the             | True: 0 | Pred: 0 ‚úÖ\n",
      "     greek           | True: 0 | Pred: 0 ‚úÖ\n",
      "     mainland        | True: 0 | Pred: 0 ‚úÖ\n",
      "     .               | True: 0 | Pred: 0 ‚úÖ\n",
      "     [SEP]           | True: 0 | Pred: 0 ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "num_examples_to_print = 5  # or however many you want\n",
    "examples_printed = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(val_dataloader):\n",
    "        input_ids, attention_mask, target_index = [item.to(device) for item in batch]\n",
    "        probs = model(input_ids, attention_mask)\n",
    "        preds = torch.argmax(torch.softmax(probs, dim=-1), dim=-1)\n",
    "\n",
    "        for j in range(input_ids.size(0)):\n",
    "            if examples_printed >= num_examples_to_print:\n",
    "                break\n",
    "\n",
    "            input_id = input_ids[j]\n",
    "            attention = attention_mask[j]\n",
    "            pred = preds[j]\n",
    "            label = target_index[j]\n",
    "\n",
    "            # Only consider real (non-padding) tokens\n",
    "            mask = (attention == 1) & (label != -100)\n",
    "            input_id = input_id[mask]\n",
    "            pred = pred[mask]\n",
    "            label = label[mask]\n",
    "\n",
    "            tokens = tokenizer.convert_ids_to_tokens(input_id)\n",
    "            sentence = tokenizer.convert_tokens_to_string(tokens)\n",
    "\n",
    "            print(f\"\\nüîπ Sentence {examples_printed + 1}:\")\n",
    "            print(f\"   Text: {sentence}\")\n",
    "            print(f\"   Tokens: {tokens}\")\n",
    "            print(f\"   True Labels:     {label.tolist()}\")\n",
    "            print(f\"   Predicted Labels:{pred.tolist()}\")\n",
    "\n",
    "            # Optional: highlight mismatches\n",
    "            print(\"   Comparison:\")\n",
    "            for tok, gold, guess in zip(tokens, label.tolist(), pred.tolist()):\n",
    "                status = \"‚úÖ\" if gold == guess else \"‚ùå\"\n",
    "                print(f\"     {tok:15} | True: {gold} | Pred: {guess} {status}\")\n",
    "\n",
    "            examples_printed += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_binary_spans(label_seq):\n",
    "    spans = []\n",
    "    start = None\n",
    "    for i, val in enumerate(label_seq):\n",
    "        if val == 1 and start is None:\n",
    "            start = i\n",
    "        elif val == 0 and start is not None:\n",
    "            spans.append((start, i - 1))\n",
    "            start = None\n",
    "    if start is not None:\n",
    "        spans.append((start, len(label_seq) - 1))\n",
    "    return spans\n",
    "\n",
    "def evaluate_binary_predictions(true_labels_list, pred_labels_list):\n",
    "    strict_match = 0\n",
    "    partial_match = 0\n",
    "    total_spans = 0\n",
    "\n",
    "    for true_seq, pred_seq in zip(true_labels_list, pred_labels_list):\n",
    "        true_spans = extract_binary_spans(true_seq)\n",
    "        pred_spans = extract_binary_spans(pred_seq)\n",
    "        total_spans += len(true_spans)\n",
    "\n",
    "        for t_start, t_end in true_spans:\n",
    "            t_range = set(range(t_start, t_end + 1))\n",
    "            match_found = False\n",
    "            for p_start, p_end in pred_spans:\n",
    "                p_range = set(range(p_start, p_end + 1))\n",
    "                if t_range == p_range:\n",
    "                    strict_match += 1\n",
    "                    match_found = True\n",
    "                    break\n",
    "                elif t_range & p_range:\n",
    "                    match_found = True\n",
    "            if match_found:\n",
    "                partial_match += 1\n",
    "\n",
    "    return {\n",
    "        \"Total Time Elements\": total_spans,\n",
    "        \"Strict Matches\": strict_match,\n",
    "        \"Partial Matches\": partial_match,\n",
    "        \"Strict Accuracy\": strict_match / total_spans if total_spans > 0 else 0,\n",
    "        \"Partial Accuracy\": partial_match / total_spans if total_spans > 0 else 0\n",
    "    }\n",
    "\n",
    "# ‚¨áÔ∏è EVALUATION CODE\n",
    "def evaluate_model(model, val_dataloader, device):\n",
    "    model.eval()\n",
    "    true_labels_all = []\n",
    "    pred_labels_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader):\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predictions = torch.argmax(outputs, dim=-1)  # shape: (B, T)\n",
    "\n",
    "            for label_seq, pred_seq, mask in zip(labels, predictions, attention_mask):\n",
    "                # Remove padding (-100) and apply attention mask\n",
    "                true_seq = [label.item() for label, m in zip(label_seq, mask) if m == 1 and label != -100]\n",
    "                pred_seq = [pred.item() for pred, m in zip(pred_seq, mask) if m == 1]\n",
    "\n",
    "                true_labels_all.append(true_seq)\n",
    "                pred_labels_all.append(pred_seq[:len(true_seq)])  # Match lengths just in case\n",
    "\n",
    "    return evaluate_binary_predictions(true_labels_all, pred_labels_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 902/902 [13:31<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluation Results:\n",
      "Total Time Elements: 4616\n",
      "Strict Matches: 3323\n",
      "Partial Matches: 4115\n",
      "Strict Accuracy: 0.720\n",
      "Partial Accuracy: 0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(model, val_dataloader, device)\n",
    "print(\"üìä Evaluation Results:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v:.3f}\" if isinstance(v, float) else f\"{k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
