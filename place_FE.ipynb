{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLPProject.ipynb  NLPProject3.ipynb manner_FE.ipynb   time_FE.ipynb\n",
      "NLPProject2.ipynb degree_FE.ipynb   place_FE.ipynb\n",
      "Notebook metadata fixed! You can now commit to GitHub.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#from google.colab import drive\n",
    "\n",
    "# Get the notebook's filename (usually matches the GitHub repo name)\n",
    "!ls *.ipynb\n",
    "notebook_name = \"NLPProject.ipynb\"  # ← Replace with your filename\n",
    "\n",
    "# Load and fix the notebook\n",
    "with open(notebook_name, 'r') as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "# Option A: Remove widgets metadata completely (recommended)\n",
    "if 'metadata' in nb and 'widgets' in nb['metadata']:\n",
    "    del nb['metadata']['widgets']\n",
    "\n",
    "# Option B: Or add the missing state key\n",
    "# if 'metadata' in nb and 'widgets' in nb['metadata']:\n",
    "#     nb['metadata']['widgets']['state'] = {}\n",
    "\n",
    "# Save the fixed version\n",
    "with open(notebook_name, 'w') as f:\n",
    "    json.dump(nb, f)\n",
    "\n",
    "print(\"Notebook metadata fixed! You can now commit to GitHub.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package framenet_v17 to\n",
      "[nltk_data]     /Users/kierstenwener/nltk_data...\n",
      "[nltk_data]   Package framenet_v17 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from operator import itemgetter\n",
    "import nltk\n",
    "from nltk.corpus import framenet as fn\n",
    "from nltk.corpus.reader.framenet import PrettyList\n",
    "nltk.download('framenet_v17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_with_place_ex = {}\n",
    "for f in fn.frames():\n",
    "    for x in f.FE:\n",
    "        if x == \"Place\":\n",
    "            frames_with_place_ex[f.name] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(text, char_labels, offsets):\n",
    "    token_labels = []\n",
    "    for start, end in offsets:\n",
    "        if start == end:\n",
    "            token_labels.append(\"O\")  # Special tokens like [CLS], [SEP]\n",
    "        else:\n",
    "            # Majority vote over character labels inside the token span\n",
    "            span_labels = char_labels[start:end]\n",
    "            if all(lab == \"O\" for lab in span_labels):\n",
    "                token_labels.append(\"O\")\n",
    "            elif span_labels[0] == \"B-Place\":\n",
    "                token_labels.append(\"B-Place\")\n",
    "            else:\n",
    "                token_labels.append(\"I-Place\")\n",
    "    return token_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kierstenwener/Desktop/NLPProject/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shapes:\n",
      "Input IDs: torch.Size([4500, 128])\n",
      "Attention Masks: torch.Size([4500, 128])\n",
      "Labels: torch.Size([4500, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from nltk.corpus import framenet as fn\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Map BIO tags to IDs\n",
    "label2id = {\"O\": 0, \"B-Place\": 1, \"I-Place\": 2}\n",
    "input_ids_list = []\n",
    "attention_masks_list = []\n",
    "labels_list = []\n",
    "\n",
    "# Find frames that include \"Place\" as a frame element\n",
    "\n",
    "for name, frame in frames_with_place_ex.items():\n",
    "    # Print the frame name for reference\n",
    "    for lu in frame.lexUnit.values():\n",
    "        #print(f\"\\nLexical Unit: {lu['name']}\")\n",
    "        lu_data = fn.lu(lu['ID'])\n",
    "        for ex in lu_data['exemplars']:\n",
    "            text = ex['text']\n",
    "            char_labels = [\"O\"] * len(text)\n",
    "            has_place_fe = False\n",
    "\n",
    "            for fe in ex['FE']:\n",
    "                for i in fe:\n",
    "                    if i[2] == \"Place\":\n",
    "                        start, end = i[0], i[1]\n",
    "                        if start < end:\n",
    "                            char_labels[start] = \"B-Place\"\n",
    "                            for i in range(start+1, end):\n",
    "                                char_labels[i] = \"I-Place\"\n",
    "                            has_place_fe = True\n",
    "            if not has_place_fe:\n",
    "                continue\n",
    "\n",
    "\n",
    "            # Tokenize\n",
    "            tokenized = tokenizer(text, return_offsets_mapping=True, truncation=True, padding=\"max_length\", max_length=128)\n",
    "            input_ids = tokenized[\"input_ids\"]\n",
    "            attention_mask = tokenized[\"attention_mask\"]\n",
    "            offsets = tokenized[\"offset_mapping\"]\n",
    "\n",
    "            # Map character-level labels to token-level labels\n",
    "            token_labels = align_labels_with_tokens(text, char_labels, offsets)\n",
    "            label2id_binary = {\"O\": 0, \"B-Place\": 1, \"I-Place\": 2}  \n",
    "            # Pad remaining labels with -100 where attention mask is 0 (i.e., padding tokens)\n",
    "\n",
    "\n",
    "            label_ids = [label2id_binary.get(lab, 0) for lab in token_labels]\n",
    "            label_ids = [\n",
    "                label if mask == 1 else -100 \n",
    "                for label, mask in zip(label_ids, attention_mask)\n",
    "            ]\n",
    "            # Store tensors\n",
    "            input_ids_list.append(torch.tensor(input_ids))\n",
    "            attention_masks_list.append(torch.tensor(attention_mask))\n",
    "            labels_list.append(torch.tensor(label_ids))\n",
    "\n",
    "# Final dataset tensors\n",
    "input_ids_tensor = torch.stack(input_ids_list)\n",
    "attention_masks_tensor = torch.stack(attention_masks_list)\n",
    "labels_tensor = torch.stack(labels_list)\n",
    "\n",
    "print(\"Tensor shapes:\")\n",
    "print(\"Input IDs:\", input_ids_tensor.shape)\n",
    "print(\"Attention Masks:\", attention_masks_tensor.shape)\n",
    "print(\"Labels:\", labels_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "dataset = TensorDataset(input_ids_tensor, attention_masks_tensor, labels_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training and testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SubsetRandomSampler\n",
    "from torch.utils.data import random_split\n",
    "# Parameters\n",
    "batch_size = 5\n",
    "validation_split = 0.5\n",
    "\n",
    "train_size = int((1 - validation_split) * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),  # Shuffle the data\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Create DataLoader for validation (without shuffling)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    sampler=SubsetRandomSampler(range(len(val_dataset))),  # Don't shuffle validation data\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "class FrameElementClassifier(nn.Module):\n",
    "    def __init__(self, bert_model='bert-base-uncased'):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model)\n",
    "        #self.query_encoder = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size)\n",
    "        self.token_projection = nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 3)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    #def forward(self, input_ids, attention_mask, role_ids, role_mask):\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Encode sentence\n",
    "        sentence_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        token_embeddings = sentence_outputs.last_hidden_state  # shape: (B, T, H)\n",
    "\n",
    "        # Project sentence tokens\n",
    "        token_embeddings = self.token_projection(token_embeddings)  # shape: (B, T, H)\n",
    "        logits = self.classifier(token_embeddings)\n",
    "\n",
    "        return logits  # Apply softmax for inference or use with CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "accuracies = []\n",
    "num_batches = 15\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FrameElementClassifier().to(device)\n",
    "#class_weights = torch.tensor([0.4, 0.6]).to(device)  # Make manner more important\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions_batch = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        input_ids, attention_mask, target_index = [item.to(device) for item in batch]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        probs = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(probs.view(-1, 3), target_index.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "post processing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def fix_bio_predictions2(predictions):\n",
    "    corrected = []\n",
    "    batch_size, seq_len = predictions.shape\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        sentence = predictions[i].tolist()\n",
    "        sentence_corrected = sentence.copy()\n",
    "\n",
    "        for j in range(seq_len-1):\n",
    "            if sentence[j] == 2:  # I-Time\n",
    "                if j == 0:\n",
    "                    # Beginning of sequence, can't be I-Time\n",
    "                    sentence_corrected[j] = 0\n",
    "\n",
    "                elif sentence[j-1] == 0:\n",
    "                    # Look ahead to see if more 2's follow\n",
    "                    if sentence[j+1] == 2:\n",
    "                        if j > 2 and sentence[j-2] == 0:\n",
    "                            sentence_corrected[j-1] = 1\n",
    "                            sentence_corrected[j] = sentence[j]\n",
    "                        else:\n",
    "                            sentence_corrected[j-1] = 2\n",
    "                            sentence_corrected[j] = sentence[j]\n",
    "                    else: \n",
    "                        sentence_corrected[j] = 0\n",
    "                else:\n",
    "                    sentence_corrected[j] = sentence[j]\n",
    "            else:\n",
    "                sentence_corrected[j] = sentence[j]\n",
    "\n",
    "\n",
    "\n",
    "        corrected.append(sentence_corrected)\n",
    "\n",
    "    return torch.tensor(corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate model with post processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (O, B-Place, I-Place):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.98      0.94      0.96      1852\n",
      "     B-Place       0.71      0.81      0.75        78\n",
      "     I-Place       0.71      0.89      0.79       242\n",
      "\n",
      "    accuracy                           0.93      2172\n",
      "   macro avg       0.80      0.88      0.84      2172\n",
      "weighted avg       0.94      0.93      0.93      2172\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1744   23   85]\n",
      " [  11   63    4]\n",
      " [  23    3  216]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(val_dataloader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        input_ids, attention_mask, target_index = [item.to(device) for item in batch]\n",
    "\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        #gives index of highest scoring class\n",
    "        predicted_tokens = torch.argmax(logits, dim=-1)\n",
    "        fixed_predictions = fix_bio_predictions2(predicted_tokens)\n",
    "\n",
    "        mask = (target_index != -100)\n",
    "\n",
    "        all_true_labels.extend(target_index[mask].view(-1).cpu().numpy())\n",
    "        all_pred_labels.extend(fixed_predictions[mask].view(-1).cpu().numpy())\n",
    "\n",
    "# Report\n",
    "print(\"Classification Report (O, B-Place, I-Place):\")\n",
    "print(classification_report(all_true_labels, all_pred_labels, target_names=['O', 'B-Place', 'I-Place']))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix for Time FE Detection')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Accuracy: 1744/1852 = 0.9417\n",
      "B-Place Accuracy: 63/78 = 0.8077\n",
      "I-Place Accuracy: 216/242 = 0.8926\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "true_np = np.array(all_true_labels)\n",
    "pred_np = np.array(all_pred_labels)\n",
    "\n",
    "for label_id, label_name in enumerate(['O', 'B-Place', 'I-Place']):\n",
    "    total = np.sum(true_np == label_id)\n",
    "    correct = np.sum((true_np == label_id) & (pred_np == label_id))\n",
    "    print(f\"{label_name} Accuracy: {correct}/{total} = {correct/total:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to find the number of FEs that we classified completely correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "def evaluate_model_postprocessed(model, val_dataloader, device):\n",
    "    model.eval()\n",
    "    true_labels_all = []\n",
    "    pred_labels_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader):\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            raw_preds = torch.argmax(outputs, dim=-1)  # (B, T)\n",
    "            fixed_preds = fix_bio_predictions2(raw_preds)  # Apply post-processing\n",
    "\n",
    "            for label_seq, pred_seq, mask in zip(labels, fixed_preds, attention_mask):\n",
    "                # Remove padding and apply attention mask\n",
    "                true_seq = [label.item() for label, m in zip(label_seq, mask) if m == 1 and label != -100]\n",
    "                pred_seq = [pred.item() for pred, m in zip(pred_seq, mask) if m == 1]\n",
    "\n",
    "                true_labels_all.append(true_seq)\n",
    "                pred_labels_all.append(pred_seq[:len(true_seq)])\n",
    "\n",
    "    return evaluate_predictions(true_labels_all, pred_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_bio_spans(label_seq):\n",
    "    spans = []\n",
    "    start = None\n",
    "\n",
    "    for i, label in enumerate(label_seq):\n",
    "        if label == 1:  # B\n",
    "            if start is not None:\n",
    "                spans.append((start, i - 1))  # close previous span\n",
    "            start = i\n",
    "        elif label == 2:\n",
    "            if start is None:\n",
    "                # Ill-formed BIO (I without B) — treat as beginning a new span\n",
    "                start = i\n",
    "        else:  # label == 0\n",
    "            if start is not None:\n",
    "                spans.append((start, i - 1))\n",
    "                start = None\n",
    "\n",
    "    if start is not None:\n",
    "        spans.append((start, len(label_seq) - 1))\n",
    "    \n",
    "    return spans\n",
    "\n",
    "def evaluate_predictions(true_labels_list, pred_labels_list):\n",
    "    strict_match = 0\n",
    "    partial_match = 0\n",
    "    total_spans = 0\n",
    "\n",
    "    for true_seq, pred_seq in zip(true_labels_list, pred_labels_list):\n",
    "        true_spans = extract_bio_spans(true_seq)\n",
    "        pred_spans = extract_bio_spans(pred_seq)\n",
    "        total_spans += len(true_spans)\n",
    "\n",
    "        for t_start, t_end in true_spans:\n",
    "            t_range = set(range(t_start, t_end + 1))\n",
    "            match_found = False\n",
    "            for p_start, p_end in pred_spans:\n",
    "                p_range = set(range(p_start, p_end + 1))\n",
    "                if t_range == p_range:\n",
    "                    strict_match += 1\n",
    "                    match_found = True\n",
    "                    break\n",
    "                elif t_range & p_range:\n",
    "                    match_found = True\n",
    "            if match_found:\n",
    "                partial_match += 1\n",
    "\n",
    "    return {\n",
    "        \"Total Time Elements\": total_spans,\n",
    "        \"Strict Matches\": strict_match,\n",
    "        \"Partial Matches\": partial_match,\n",
    "        \"Strict Accuracy\": strict_match / total_spans if total_spans > 0 else 0,\n",
    "        \"Partial Accuracy\": partial_match / total_spans if total_spans > 0 else 0\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "  0%|          | 0/450 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [01:42<00:00,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Post-Processed Evaluation Results:\n",
      "Total Time Elements: 2326\n",
      "Strict Matches: 1710\n",
      "Partial Matches: 2026\n",
      "Strict Accuracy: 0.735\n",
      "Partial Accuracy: 0.871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model_postprocessed(model, val_dataloader, device)\n",
    "\n",
    "print(\"📊 Post-Processed Evaluation Results:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v:.3f}\" if isinstance(v, float) else f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try some random sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           O\n",
      "they            O\n",
      "stayed          O\n",
      "at              B-Manner\n",
      "a               I-Manner\n",
      "cozy            O\n",
      "bed             B-Manner\n",
      "and             I-Manner\n",
      "breakfast       I-Manner\n",
      "overlooking     I-Manner\n",
      "the             I-Manner\n",
      "lake            I-Manner\n",
      ".               O\n",
      "[SEP]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           B-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           B-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           B-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           B-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# 2. Prepare a test sentence\n",
    "text = \"They stayed at a cozy bed and breakfast overlooking the lake.\"\n",
    "\n",
    "# Tokenize with offsets to possibly map back later (optional here)\n",
    "encoding = tokenizer(text, return_tensors=\"pt\", return_offsets_mapping=True,\n",
    "                     truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "input_ids = encoding[\"input_ids\"]        # shape: (1, 128)\n",
    "attention_mask = encoding[\"attention_mask\"]\n",
    "offsets = encoding[\"offset_mapping\"]\n",
    "\n",
    "# 3. Pass through the model\n",
    "with torch.no_grad():\n",
    "    logits = model(input_ids, attention_mask)  # shape: (1, 128, 3)\n",
    "    predictions2 = torch.argmax(logits, dim=-1)  # shape: (1, 128)\n",
    "    fixed_predictions = fix_bio_predictions2(predictions2)\n",
    "\n",
    "id2label = {0: \"O\", 1: \"B-Manner\", 2: \"I-Manner\"}\n",
    "predicted_tags2 = [id2label[i.item()] for i in fixed_predictions[0]]\n",
    "\n",
    "# 5. Get back tokens for visualization (optional)\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "for tok, tag in zip(tokens, predicted_tags2):\n",
    "    print(f\"{tok:15} {tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using post_processing2 function, frequently dont correctly identify the B in a frame element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Post processing tecnique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def fix_bio_predictions3(predictions):\n",
    "    corrected = []\n",
    "    batch_size, seq_len = predictions.shape\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        sentence = predictions[i].tolist()\n",
    "        sentence_corrected = sentence.copy()\n",
    "\n",
    "        for j in range(seq_len):\n",
    "            tag = sentence[j]\n",
    "\n",
    "            if tag == 2:  # I-tag\n",
    "                if j == 0:\n",
    "                    # Can't start with I -> make it O\n",
    "                    sentence_corrected[j] = 0\n",
    "\n",
    "                elif sentence_corrected[j - 1] == 0:\n",
    "                    # Pattern: O I ...\n",
    "                    # Check if a run of I-tags follows\n",
    "                    run_length = 1\n",
    "                    k = j + 1\n",
    "                    while k < seq_len and sentence[k] == 2:\n",
    "                        run_length += 1\n",
    "                        k += 1\n",
    "\n",
    "                    if run_length >= 1:\n",
    "                        # Change the O (at j-1) to B\n",
    "                        sentence_corrected[j - 1] = 1\n",
    "                    else:\n",
    "                        # Lone I -> make it O\n",
    "                        sentence_corrected[j] = 0\n",
    "\n",
    "        corrected.append(sentence_corrected)\n",
    "\n",
    "    return torch.tensor(corrected, device=predictions.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "def evaluate_model_postprocessed2(model, val_dataloader, device):\n",
    "    model.eval()\n",
    "    true_labels_all = []\n",
    "    pred_labels_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader):\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            raw_preds = torch.argmax(outputs, dim=-1)  # (B, T)\n",
    "            fixed_preds = fix_bio_predictions3(raw_preds)  # Apply post-processing\n",
    "\n",
    "            for label_seq, pred_seq, mask in zip(labels, fixed_preds, attention_mask):\n",
    "                # Remove padding and apply attention mask\n",
    "                true_seq = [label.item() for label, m in zip(label_seq, mask) if m == 1 and label != -100]\n",
    "                pred_seq = [pred.item() for pred, m in zip(pred_seq, mask) if m == 1]\n",
    "\n",
    "                true_labels_all.append(true_seq)\n",
    "                pred_labels_all.append(pred_seq[:len(true_seq)])\n",
    "\n",
    "    return evaluate_predictions(true_labels_all, pred_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [01:42<00:00,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Post-Processed Evaluation Results:\n",
      "Total Time Elements: 2326\n",
      "Strict Matches: 1708\n",
      "Partial Matches: 2061\n",
      "Strict Accuracy: 0.734\n",
      "Partial Accuracy: 0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results2 = evaluate_model_postprocessed2(model, val_dataloader, device)\n",
    "\n",
    "print(\"📊 Post-Processed Evaluation Results:\")\n",
    "for k, v in results2.items():\n",
    "    print(f\"{k}: {v:.3f}\" if isinstance(v, float) else f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slight increase in strict accuracy (.747->.748)\n",
    "larger increase in partial accuracy (.916->.932)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test some random sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           O\n",
      "i               O\n",
      "want            O\n",
      "to              O\n",
      "go              O\n",
      "to              O\n",
      "the             O\n",
      "blue            O\n",
      "tavern          O\n",
      "across          B-Manner\n",
      "town            I-Manner\n",
      "[SEP]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           B-Manner\n",
      "[PAD]           B-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           B-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           B-Manner\n",
      "[PAD]           I-Manner\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n",
      "[PAD]           O\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# 2. Prepare a test sentence\n",
    "text = \"I want to go to the blue tavern across town\"\n",
    "\n",
    "# Tokenize with offsets to possibly map back later (optional here)\n",
    "encoding = tokenizer(text, return_tensors=\"pt\", return_offsets_mapping=True,\n",
    "                     truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "input_ids = encoding[\"input_ids\"]        # shape: (1, 128)\n",
    "attention_mask = encoding[\"attention_mask\"]\n",
    "offsets = encoding[\"offset_mapping\"]\n",
    "\n",
    "# 3. Pass through the model\n",
    "with torch.no_grad():\n",
    "    logits = model(input_ids, attention_mask)  # shape: (1, 128, 3)\n",
    "    predictions2 = torch.argmax(logits, dim=-1)  # shape: (1, 128)\n",
    "    fixed_preds = fix_bio_predictions3(predictions2)\n",
    "\n",
    "id2label = {0: \"O\", 1: \"B-Manner\", 2: \"I-Manner\"}\n",
    "predicted_tags2 = [id2label[i.item()] for i in fixed_preds[0]]\n",
    "\n",
    "# 5. Get back tokens for visualization (optional)\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "for tok, tag in zip(tokens, predicted_tags2):\n",
    "    print(f\"{tok:15} {tag}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
